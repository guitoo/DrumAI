{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from librosa.core import resample, load\n",
    "from librosa.util import fix_length\n",
    "from librosa import feature\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm as nb_tqdm\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import umap\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "from IPython.display import display\n",
    "import ipywidgets\n",
    "from ipywidgets import Output, VBox\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('full.csv',index_col=0)\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>dir_1</th>\n",
       "      <th>class_Hat</th>\n",
       "      <th>subclass_Hat_Open</th>\n",
       "      <th>subclass_Hat_Close</th>\n",
       "      <th>subclass_Hat_Foot</th>\n",
       "      <th>class_Bongo</th>\n",
       "      <th>class_Cymbal</th>\n",
       "      <th>subclass_Cymbal_Crash</th>\n",
       "      <th>subclass_Cymbal_Ride</th>\n",
       "      <th>...</th>\n",
       "      <th>subclass_Shaken_Maracas</th>\n",
       "      <th>class_Cajon</th>\n",
       "      <th>class_clave</th>\n",
       "      <th>dir_2</th>\n",
       "      <th>subclass_Snare_Off</th>\n",
       "      <th>subclass_Snare_On</th>\n",
       "      <th>subclass_Snare_Side</th>\n",
       "      <th>subclass_Snare_Flam</th>\n",
       "      <th>subclass_Snare_Brush</th>\n",
       "      <th>subclass_Cymbal_Trash</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>path</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>./Samples/200-drum-machines/Yamaha RX-11/MaxV - RX11 OPHAT2.wav</th>\n",
       "      <td>MaxV - RX11 OPHAT2.wav</td>\n",
       "      <td>Yamaha RX-11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./Samples/200-drum-machines/Yamaha RX-11/MaxV - RX11 BD3.wav</th>\n",
       "      <td>MaxV - RX11 BD3.wav</td>\n",
       "      <td>Yamaha RX-11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./Samples/200-drum-machines/Yamaha RX-11/MaxV - RX11 BD2.wav</th>\n",
       "      <td>MaxV - RX11 BD2.wav</td>\n",
       "      <td>Yamaha RX-11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./Samples/200-drum-machines/Yamaha RX-11/MaxV - RX11 CLHAT2.wav</th>\n",
       "      <td>MaxV - RX11 CLHAT2.wav</td>\n",
       "      <td>Yamaha RX-11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./Samples/200-drum-machines/Yamaha RX-11/MaxV - RX11 RIDE.wav</th>\n",
       "      <td>MaxV - RX11 RIDE.wav</td>\n",
       "      <td>Yamaha RX-11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./Samples/200-drum-machines/Yamaha RX-11/MaxV - RX11 CLAP2.wav</th>\n",
       "      <td>MaxV - RX11 CLAP2.wav</td>\n",
       "      <td>Yamaha RX-11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./Samples/200-drum-machines/Yamaha RX-11/MaxV - RX11 MED SN.wav</th>\n",
       "      <td>MaxV - RX11 MED SN.wav</td>\n",
       "      <td>Yamaha RX-11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./Samples/200-drum-machines/Yamaha RX-11/MaxV - RX11 CLAP1.wav</th>\n",
       "      <td>MaxV - RX11 CLAP1.wav</td>\n",
       "      <td>Yamaha RX-11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./Samples/200-drum-machines/Yamaha RX-11/MaxV - RX11 RIM2.wav</th>\n",
       "      <td>MaxV - RX11 RIM2.wav</td>\n",
       "      <td>Yamaha RX-11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./Samples/200-drum-machines/Yamaha RX-11/MaxV - RX11 LITE SN.wav</th>\n",
       "      <td>MaxV - RX11 LITE SN.wav</td>\n",
       "      <td>Yamaha RX-11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   filename  \\\n",
       "path                                                                          \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...   MaxV - RX11 OPHAT2.wav   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...      MaxV - RX11 BD3.wav   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...      MaxV - RX11 BD2.wav   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...   MaxV - RX11 CLHAT2.wav   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...     MaxV - RX11 RIDE.wav   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...    MaxV - RX11 CLAP2.wav   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...   MaxV - RX11 MED SN.wav   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...    MaxV - RX11 CLAP1.wav   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...     MaxV - RX11 RIM2.wav   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...  MaxV - RX11 LITE SN.wav   \n",
       "\n",
       "                                                           dir_1  class_Hat  \\\n",
       "path                                                                          \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...  Yamaha RX-11        1.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...  Yamaha RX-11        0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...  Yamaha RX-11        0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...  Yamaha RX-11        1.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...  Yamaha RX-11        0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...  Yamaha RX-11        0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...  Yamaha RX-11        0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...  Yamaha RX-11        0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...  Yamaha RX-11        0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...  Yamaha RX-11        0.0   \n",
       "\n",
       "                                                    subclass_Hat_Open  \\\n",
       "path                                                                    \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                1.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                0.0   \n",
       "\n",
       "                                                    subclass_Hat_Close  \\\n",
       "path                                                                     \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                 1.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                 0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                 0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                 1.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                 0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                 0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                 0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                 0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                 0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                 0.0   \n",
       "\n",
       "                                                    subclass_Hat_Foot  \\\n",
       "path                                                                    \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                0.0   \n",
       "\n",
       "                                                    class_Bongo  class_Cymbal  \\\n",
       "path                                                                            \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...          0.0           0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...          0.0           0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...          0.0           0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...          0.0           0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...          0.0           1.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...          0.0           0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...          0.0           0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...          0.0           0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...          0.0           0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...          0.0           0.0   \n",
       "\n",
       "                                                    subclass_Cymbal_Crash  \\\n",
       "path                                                                        \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                    0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                    0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                    0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                    0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                    0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                    0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                    0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                    0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                    0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                    0.0   \n",
       "\n",
       "                                                    subclass_Cymbal_Ride  ...  \\\n",
       "path                                                                      ...   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                   0.0  ...   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                   0.0  ...   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                   0.0  ...   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                   0.0  ...   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                   1.0  ...   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                   0.0  ...   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                   0.0  ...   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                   0.0  ...   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                   0.0  ...   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                   0.0  ...   \n",
       "\n",
       "                                                    subclass_Shaken_Maracas  \\\n",
       "path                                                                          \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                      0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                      0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                      0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                      0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                      0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                      0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                      0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                      0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                      0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                      0.0   \n",
       "\n",
       "                                                    class_Cajon  class_clave  \\\n",
       "path                                                                           \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...          0.0          0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...          0.0          0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...          0.0          0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...          0.0          0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...          0.0          0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...          0.0          0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...          0.0          0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...          0.0          0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...          0.0          0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...          0.0          0.0   \n",
       "\n",
       "                                                    dir_2  subclass_Snare_Off  \\\n",
       "path                                                                            \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...      0                 0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...      0                 0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...      0                 0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...      0                 0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...      0                 0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...      0                 0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...      0                 0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...      0                 0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...      0                 0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...      0                 0.0   \n",
       "\n",
       "                                                    subclass_Snare_On  \\\n",
       "path                                                                    \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                0.0   \n",
       "\n",
       "                                                    subclass_Snare_Side  \\\n",
       "path                                                                      \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                  0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                  0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                  0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                  0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                  0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                  0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                  0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                  0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                  0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                  0.0   \n",
       "\n",
       "                                                    subclass_Snare_Flam  \\\n",
       "path                                                                      \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                  0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                  0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                  0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                  0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                  0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                  0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                  0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                  0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                  0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                  0.0   \n",
       "\n",
       "                                                    subclass_Snare_Brush  \\\n",
       "path                                                                       \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                   0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                   0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                   0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                   0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                   0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                   0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                   0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                   0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                   0.0   \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                   0.0   \n",
       "\n",
       "                                                    subclass_Cymbal_Trash  \n",
       "path                                                                       \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                    0.0  \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                    0.0  \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                    0.0  \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                    0.0  \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                    0.0  \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                    0.0  \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                    0.0  \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                    0.0  \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                    0.0  \n",
       "./Samples/200-drum-machines/Yamaha RX-11/MaxV -...                    0.0  \n",
       "\n",
       "[10 rows x 45 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20869/20869 [28:08<00:00, 12.36it/s] \n"
     ]
    }
   ],
   "source": [
    "SR=22050\n",
    "rms_list = []\n",
    "rms_cent_list = []\n",
    "zero_cross_list = []\n",
    "spect_cent_list = []\n",
    "spect_ro_list = []\n",
    "spect_cont_list = []\n",
    "mfcc_list = []\n",
    "index_list = []\n",
    "#data = data.sample(frac=0.2)\n",
    "for index, file in tqdm(zip(df.index, df['path']), total=len(df.index), position=0, leave=True):\n",
    "    try:\n",
    "        sound, _ = load(file, sr=SR)\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    index_list.append(index)\n",
    "    \n",
    "    rms = feature.rms(sound)[0]\n",
    "     #normalize by rms of attack frame\n",
    "    rms_centroid = (rms * np.arange(len(rms))).sum() / rms.sum()\n",
    "#     features.loc[index, 'rms_centroid'] = rms_centroid\n",
    "    rms_cent_list.append(rms_centroid)\n",
    "    \n",
    "    sound = sound/rms.max()\n",
    "    sound = fix_length(sound, 1024*(SR//1024))\n",
    "    \n",
    "    zero_cr = feature.zero_crossing_rate(sound)[0]\n",
    "#     columns = ['zero_cr_' + str(x) for x in range(zero_cr.shape[0])]\n",
    "#     for col, value in zip(columns, zero_cr):\n",
    "#         features.loc[index, col] = value\n",
    "    zero_cross_list.append(zero_cr)\n",
    "        \n",
    "    spect_cent = feature.spectral_centroid(sound, sr=SR)[0]\n",
    "#     columns = ['spect_cent_' + str(x) for x in range(spect_cent.shape[0])]\n",
    "#     for col, value in zip(columns, spect_cent):\n",
    "#         features.loc[index, col] = value\n",
    "    spect_cent_list.append(spect_cent)\n",
    "        \n",
    "    spect_ro = feature.spectral_rolloff(sound, sr=SR)[0]\n",
    "#     columns = ['spect_ro_' + str(x) for x in range(spect_ro.shape[0])]\n",
    "#     for col, value in zip(columns, spect_ro):\n",
    "#         features.loc[index, col] = value\n",
    "    spect_ro_list.append(spect_ro)\n",
    "        \n",
    "    rms = feature.rms(sound)[0]\n",
    "#     columns = ['rms_' + str(x) for x in range(rms.shape[0])]\n",
    "#     for col, value in zip(columns, rms):\n",
    "#         #features.loc[index, col] = value\n",
    "#         features.loc[index, 'norm_'+ col] = value\n",
    "    rms_list.append(rms)\n",
    "    \n",
    "        \n",
    "    spect_cont = feature.spectral_contrast(sound, sr=SR)\n",
    "#     for i in range (spect_cont.shape[0]):\n",
    "#         for j in range (spect_cont.shape[1]):\n",
    "#             col = 'spec_cont_' + str(i) + '_' + str(j)\n",
    "#             features.loc[index, col] = spect_cont[i][j]\n",
    "    spect_cont_list.append(spect_cont)\n",
    "    \n",
    "    mfcc = feature.mfcc(sound, sr=SR)\n",
    "    mfcc_list.append(mfcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "rms = np.stack(rms_list)\n",
    "rms_cent = np.stack(rms_cent_list)\n",
    "zero_cross = np.stack(zero_cross_list)\n",
    "spect_cent = np.stack(spect_cent_list)\n",
    "spect_ro = np.stack(spect_ro_list)\n",
    "spect_cont = np.stack(spect_cont_list)\n",
    "mfcc = np.stack(mfcc_list)\n",
    "index = np.stack(index_list)\n",
    "\n",
    "np.save('feature_rms.npy', rms)\n",
    "np.save('feature_rms_centroid.npy', rms_cent)\n",
    "np.save('feature_zero_crossing_rate.npy', zero_cross)\n",
    "np.save('feature_spectral_centroid.npy', spect_cent)\n",
    "np.save('feature_spectral_rolloff.npy', spect_ro)\n",
    "np.save('feature_spectral_contour.npy', spect_cont)\n",
    "np.save('feature_mfcc.npy', mfcc)\n",
    "np.save('index.npy', index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms = np.load('feature_rms.npy')\n",
    "rms_cent = np.load('feature_rms_centroid.npy')\n",
    "zero_cross = np.load('feature_zero_crossing_rate.npy')\n",
    "spect_cent = np.load('feature_spectral_centroid.npy')\n",
    "spect_ro = np.load('feature_spectral_rolloff.npy')\n",
    "spect_cont = np.load('feature_spectral_contour.npy')\n",
    "mfcc = np.load('feature_mfcc.npy')\n",
    "index = np.load('index.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20869,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20869, 474)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = index.shape[0]\n",
    "features = np.hstack([\n",
    "    rms.reshape(size,-1),\n",
    "    rms_cent.reshape(size,-1),\n",
    "    zero_cross.reshape(size,-1),\n",
    "    spect_cent.reshape(size,-1),\n",
    "    spect_ro.reshape(size,-1),\n",
    "    spect_cont.reshape(size,-1),\n",
    "                  ])\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Int64Index([    0,     1,     2,     3,     4,     5,     6,     7,     8,\\n                9,\\n            ...\\n            20860, 20861, 20862, 20863, 20864, 20865, 20866, 20867, 20868,\\n            20869],\\n           dtype='int64', name='path', length=20869)] are in the [index]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-adacabb5297a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/DrumAI/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/DrumAI/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1097\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot index with multidimensional key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m             \u001b[0;31m# nested tuple slicing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/DrumAI/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0;31m# A collection of keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m         \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m         return self.obj._reindex_with_indexers(\n\u001b[1;32m   1039\u001b[0m             \u001b[0;34m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/DrumAI/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1252\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1255\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/DrumAI/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m                 \u001b[0maxis_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1298\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1300\u001b[0m             \u001b[0;31m# We (temporarily) allow for some missing keys with .loc, except in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Int64Index([    0,     1,     2,     3,     4,     5,     6,     7,     8,\\n                9,\\n            ...\\n            20860, 20861, 20862, 20863, 20864, 20865, 20866, 20867, 20868,\\n            20869],\\n           dtype='int64', name='path', length=20869)] are in the [index]\""
     ]
    }
   ],
   "source": [
    "df = df.loc[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "features.to_csv('features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv('features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [c for c in df.columns if c.startswith('class_')]\n",
    "cymb_classes = [c for c in df.columns if c.startswith('subclass_Cymbal')]\n",
    "shak_classes = [c for c in df.columns if c.startswith('subclass_Shaken')]\n",
    "hat_classes = [c for c in df.columns if c.startswith('subclass_Hat')]\n",
    "\n",
    "all_classes = classes + cymb_classes + shak_classes + hat_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cymb_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_df = pd.DataFrame()\n",
    "\n",
    "class_df['class'] = df[all_classes].idxmax(axis=1)\n",
    "\n",
    "mask = df[all_classes].sum(axis=1) == 0\n",
    "class_df.loc[mask, 'class'] = 'Error'\n",
    "\n",
    "cymbales = (df['class_Cymbal'] == 1) & (df[cymb_classes].sum(axis=1) > 0)\n",
    "class_df.loc[cymbales, 'class'] = df.loc[cymbales, cymb_classes].idxmax(axis=1)\n",
    "\n",
    "shaken = (df['class_Shaken'] == 1) & (df[shak_classes].sum(axis=1) > 0)\n",
    "class_df.loc[shaken, 'class'] = df.loc[shaken, shak_classes].idxmax(axis=1)\n",
    "\n",
    "hats = (df['class_Hat'] == 1) & (df[hat_classes].sum(axis=1) > 0)\n",
    "class_df.loc[hats, 'class'] = df.loc[hats, hat_classes].idxmax(axis=1)\n",
    "# class_df['class'] = df[hat_classes + ['class_Hat']].idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[shaken, shak_classes].idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_df[class_df['class'].str.startswith('subclass_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dysplay_embedding(x, y, classes, files):\n",
    "    embedding_vae_df = pd.DataFrame({\n",
    "        'x': x,\n",
    "        'y': y,\n",
    "        'class': classes,\n",
    "        'file': files    \n",
    "                         })\n",
    "    \n",
    "    scatter = px.scatter(\n",
    "        embedding_vae_df,\n",
    "        x='x',\n",
    "        y='y',\n",
    "        color='class',\n",
    "        hover_data=['file']\n",
    "    )\n",
    "    figure = go.FigureWidget(scatter)\n",
    "\n",
    "    out = Output()\n",
    "\n",
    "    @out.capture(clear_output=False, wait=True)\n",
    "    def play_sound(trace, points, selector):\n",
    "        if len(points.point_inds) != 1:\n",
    "           return\n",
    "        #print(points)\n",
    "        out.clear_output()\n",
    "        path = trace.customdata[points.point_inds[0]][0]\n",
    "        #print(path)\n",
    "        sound, sr = load(path)\n",
    "        IPython.display.display(IPython.display.Audio(sound, rate=sr, autoplay=True))\n",
    "\n",
    "    for trace in figure.data:\n",
    "        trace.on_click(play_sound)\n",
    "\n",
    "\n",
    "    box = VBox([figure, out])\n",
    "    display(box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler \n",
    "# scaler = StandardScaler()\n",
    "# features_scaled = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-e7cf37de5c14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mreducer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mumap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUMAP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreducer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'features_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "reducer = umap.UMAP()\n",
    "embedding = reducer.fit_transform(features_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_df = class_df.loc[index]\n",
    "class_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = df.loc[index,'path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_onehot_df = df[all_classes]\n",
    "classes_onehot_df = classes_onehot_df.loc[index]\n",
    "nb_classes =  classes_onehot_df.shape[1]\n",
    "nb_features = features.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embedding' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-58aa859ec84d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m dysplay_embedding(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0membedding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0membedding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mclass_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'embedding' is not defined"
     ]
    }
   ],
   "source": [
    "dysplay_embedding(\n",
    "    embedding[:, 0],\n",
    "    embedding[:, 1],\n",
    "    class_df['class'].values,\n",
    "    filename\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rms_cent = rms_cent.reshape(-1, 1)\n",
    "# rms = rms.reshape(-1,rms.shape[1], 1)\n",
    "features_input = dict(\n",
    "    rms=rms,\n",
    "    rms_centroid=rms_cent,\n",
    "    zero_crossing=zero_cross,\n",
    "    spectral_centroid=spect_cent,\n",
    "    spectral_rolloff=spect_ro,\n",
    "    spectral_contour=spect_cont,\n",
    "    mfcc=mfcc\n",
    ")\n",
    "for key, feature in list(features_input.items()):\n",
    "    if feature.shape[-1] !=1:\n",
    "        features_input[key] = np.expand_dims(feature, axis=feature.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = {}\n",
    "features_scaled = {}\n",
    "for key, feature in list(features_input.items()):\n",
    "    scaler[key] = {}\n",
    "    scaler[key]['max'] = max(feature.max(), -feature.min())\n",
    "    features_scaled[key] = feature/scaler[key]['max']\n",
    "#     scaler[key]['mean'] = feature.mean()\n",
    "# #     scaler[key]['mean'] = feature.mean(axis=0)\n",
    "#     f = feature-scaler[key]['mean']\n",
    "#     scaler[key]['std'] = f.std()\n",
    "# #     scaler[key]['std'] = f.std(axis=0)\n",
    "#     features_scaled[key] = f/scaler[key]['std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, feature in list(features_scaled.items()):\n",
    "    print(key, feature.min(), feature.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in features_scaled.items():\n",
    "    print(f\"{key} shape: {value.shape[1:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim=2\n",
    "def build_encoder():\n",
    "    rms_input = keras.Input(shape=features_input['rms'].shape[1:])\n",
    "    rms_cent_input = keras.Input(shape=features_input['rms_centroid'].shape[1:])\n",
    "    zero_cross_input = keras.Input(shape=features_input['zero_crossing'].shape[1:])\n",
    "    spect_cent_input = keras.Input(shape=features_input['spectral_centroid'].shape[1:])\n",
    "    spect_ro_input = keras.Input(shape=features_input['spectral_rolloff'].shape[1:])\n",
    "    spect_cont_input = keras.Input(shape=features_input['spectral_contour'].shape[1:])\n",
    "    mfcc_input = keras.Input(shape=features_input['mfcc'].shape[1:])\n",
    "\n",
    "    x=rms_input\n",
    "    for filters in [4,8,16]:\n",
    "        x = layers.Conv1D(filters,3,activation='relu',padding='same')(x)\n",
    "        x = layers.MaxPooling1D(2)(x)\n",
    "    rms_out = layers.Flatten()(x)\n",
    "\n",
    "    x=zero_cross_input\n",
    "    for filters in [4,8,16]:\n",
    "        x = layers.Conv1D(filters,3,activation='relu',padding='same')(x)\n",
    "        x = layers.MaxPooling1D(2)(x)\n",
    "    zero_cross_out = layers.Flatten()(x)\n",
    "\n",
    "    x=spect_cent_input\n",
    "    for filters in [4,8,16]:\n",
    "        x = layers.Conv1D(filters,3,activation='relu',padding='same')(x)\n",
    "        x = layers.MaxPooling1D(2)(x)\n",
    "    spect_cent_out = layers.Flatten()(x)\n",
    "\n",
    "    x=spect_ro_input\n",
    "    for filters in [4,8,16]:\n",
    "        x = layers.Conv1D(filters,3,activation='relu',padding='same')(x)\n",
    "        x = layers.MaxPooling1D(2)(x)\n",
    "    spect_ro_out = layers.Flatten()(x)\n",
    "\n",
    "    x=mfcc_input\n",
    "    for filters in [8,16,32]:\n",
    "        x = layers.Conv2D(filters, (3,3), activation='tanh',padding='same')(x)\n",
    "        x = layers.MaxPooling2D((2,2))(x)\n",
    "    x = layers.MaxPooling2D((2,1))(x)\n",
    "    mfcc_out = layers.Flatten()(x)\n",
    "\n",
    "    x=spect_cont_input\n",
    "    for filters in [4,8]:\n",
    "        x = layers.Conv2D(filters, (3,3), activation='relu',padding='same')(x)\n",
    "        x = layers.MaxPooling2D((2,2))(x)\n",
    "    x = layers.Conv2D(16, (3,3), activation='relu',padding='same')(x)\n",
    "    x = layers.MaxPooling2D((1,2))(x)\n",
    "    spect_cont_out = layers.Flatten()(x)\n",
    "\n",
    "    concat = layers.Concatenate()((\n",
    "        rms_cent_input, \n",
    "        rms_out, zero_cross_out, \n",
    "        spect_cent_out,\n",
    "        spect_ro_out, \n",
    "        mfcc_out, \n",
    "        spect_cont_out\n",
    "    ))\n",
    "\n",
    "    x= concat\n",
    "    for size in [32, 16, 8]:\n",
    "        x = layers.Dense(size, activation='relu')(x)\n",
    "    z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "    z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "    z = Sampling()([z_mean, z_log_var])\n",
    "\n",
    "    inputs = dict(\n",
    "        rms=rms_input,\n",
    "        rms_centroid=rms_cent_input,\n",
    "        zero_crossing=zero_cross_input,\n",
    "        spectral_centroid=spect_cent_input,\n",
    "        spectral_rolloff=spect_ro_input,\n",
    "        spectral_contour=spect_cont_input,\n",
    "        mfcc=mfcc_input,\n",
    "    )\n",
    "    outputs =  (z_mean, z_log_var, z)\n",
    "\n",
    "    encoder = keras.Model(inputs, outputs, name=\"encoder\")\n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_decoder():\n",
    "    latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "\n",
    "    x = layers.Dense(1 * 6 * 16, activation=\"relu\")(latent_inputs)\n",
    "    x = layers.Reshape((1, 6, 16))(x)\n",
    "    x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=(2,2), padding=\"same\")(x)\n",
    "    x = layers.Conv2DTranspose(16, 3, activation=\"relu\", strides=(2,2), padding=\"same\")(x)\n",
    "    x = layers.Conv2DTranspose(1, 3, activation=\"sigmoid\", strides=(2,2), padding=\"same\")(x)\n",
    "    x = layers.Cropping2D(cropping=((0,1),(2,3)))(x)\n",
    "    spect_cont_out = x\n",
    "\n",
    "    x = layers.Dense(16, activation=\"relu\")(latent_inputs)\n",
    "    x = layers.Dense(3 * 6 * 16, activation=\"relu\")(x)\n",
    "    x = layers.Reshape((3, 6, 16))(x)\n",
    "    x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=(2,2), padding=\"same\")(x)\n",
    "    x = layers.Conv2DTranspose(16, 3, activation=\"relu\", strides=(2,2), padding=\"same\")(x)\n",
    "    x = layers.Conv2DTranspose(1, 3, activation=\"tanh\", strides=(2,2), padding=\"same\")(x)\n",
    "    x = layers.Cropping2D(cropping=((2,2),(2,3)))(x)\n",
    "    mfcc_out = x\n",
    "\n",
    "    # x = layers.Dense(16, activation=\"relu\")(latent_inputs)\n",
    "    # x = layers.Dense(32, activation=\"relu\")(x)\n",
    "    # x = layers.Dense(64, activation=\"relu\")(x)\n",
    "    # x = layers.Dense(20*43, activation=\"relu\")(x)\n",
    "    # mfcc_out = layers.Reshape((20, 43, 1))(x)\n",
    "\n",
    "    x = layers.Dense(6 * 16, activation=\"relu\")(latent_inputs)\n",
    "    x = layers.Reshape((6, 16))(x)\n",
    "    x = layers.Conv1DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "    x = layers.Conv1DTranspose(16, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "    x = layers.Conv1DTranspose(1, 3, activation=\"sigmoid\", strides=2, padding=\"same\")(x)\n",
    "    x = layers.Cropping1D(cropping=(2,3))(x)\n",
    "    rms_out = x\n",
    "\n",
    "    x = layers.Dense(6 * 16, activation=\"relu\")(latent_inputs)\n",
    "    x = layers.Reshape((6, 16))(x)\n",
    "    x = layers.Conv1DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "    x = layers.Conv1DTranspose(16, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "    x = layers.Conv1DTranspose(1, 3, activation=\"sigmoid\", strides=2, padding=\"same\")(x)\n",
    "    x = layers.Cropping1D(cropping=(2,3))(x)\n",
    "    zero_cross_out = x\n",
    "\n",
    "    x = layers.Dense(6 * 16, activation=\"relu\")(latent_inputs)\n",
    "    x = layers.Reshape((6, 16))(x)\n",
    "    x = layers.Conv1DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "    x = layers.Conv1DTranspose(16, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "    x = layers.Conv1DTranspose(1, 3, activation=\"sigmoid\", strides=2, padding=\"same\")(x)\n",
    "    x = layers.Cropping1D(cropping=(2,3))(x)\n",
    "    spect_cent_out = x\n",
    "\n",
    "    x = layers.Dense(6 * 16, activation=\"relu\")(latent_inputs)\n",
    "    x = layers.Reshape((6, 16))(x)\n",
    "    x = layers.Conv1DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "    x = layers.Conv1DTranspose(16, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "    x = layers.Conv1DTranspose(1, 3, activation=\"sigmoid\", strides=2, padding=\"same\")(x)\n",
    "    x = layers.Cropping1D(cropping=(2,3))(x)\n",
    "    spect_ro_out = x\n",
    "\n",
    "    for size in (4,8,16):\n",
    "        x = layers.Dense(size, activation=\"relu\")(latent_inputs)\n",
    "    rms_cent_out = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "#     x = layers.Lambda(lambda x: tf.atan2(*tf.split(x,2, axis=-1)))(latent_inputs)\n",
    "    x = layers.Dense(8, activation=\"sigmoid\")(latent_inputs)\n",
    "    class_out = layers.Dense(nb_classes, activation=\"sigmoid\")(x)\n",
    "\n",
    "    outputs = dict(\n",
    "        rms=rms_out,\n",
    "        rms_centroid=rms_cent_out,\n",
    "        zero_crossing=zero_cross_out,\n",
    "        spectral_centroid=spect_cent_out,\n",
    "        spectral_rolloff=spect_ro_out,\n",
    "        spectral_contour=spect_cont_out,\n",
    "        mfcc=mfcc_out,\n",
    "        classes=class_out\n",
    "    )\n",
    "    decoder_outputs = x\n",
    "    #decoder_outputs = layers.Dense(input_dim, activation=\"relu\")(x)\n",
    "    decoder = keras.Model(latent_inputs, outputs, name=\"decoder\")\n",
    "    return decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "build_decoder().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def train_step(self, data):\n",
    "        if isinstance(data, tuple):\n",
    "            data = data[0]\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = encoder(data)\n",
    "            reconstruction = decoder(z)\n",
    "            \n",
    "            rms_loss = tf.reduce_mean(\n",
    "                keras.losses.binary_crossentropy(data['rms'], reconstruction['rms'])\n",
    "            )\n",
    "            rms_loss *= 43\n",
    "            zero_crossing_loss = tf.reduce_mean(\n",
    "                keras.losses.binary_crossentropy(data['zero_crossing'], reconstruction['zero_crossing'])\n",
    "            )\n",
    "            zero_crossing_loss *= 43\n",
    "            spectral_centroid_loss = tf.reduce_mean(\n",
    "                keras.losses.binary_crossentropy(data['spectral_centroid'], reconstruction['spectral_centroid'])\n",
    "            )\n",
    "            spectral_centroid_loss *= 43\n",
    "            spectral_rolloff_loss = tf.reduce_mean(\n",
    "                keras.losses.binary_crossentropy(data['spectral_rolloff'], reconstruction['spectral_rolloff'])\n",
    "            )\n",
    "            spectral_rolloff_loss *= 43\n",
    "            mfcc_loss = tf.reduce_mean(\n",
    "                keras.losses.MSE(data['mfcc'], reconstruction['mfcc'])\n",
    "            )\n",
    "            mfcc_loss *= 20*43\n",
    "            spectral_contour_loss = tf.reduce_mean(\n",
    "                keras.losses.MSE(data['spectral_contour'], reconstruction['spectral_contour'])\n",
    "            )\n",
    "            spectral_contour_loss *= 7*43\n",
    "            rms_cent_loss = tf.reduce_mean(\n",
    "                keras.losses.binary_crossentropy(data['rms_centroid'], reconstruction['rms_centroid'])\n",
    "            )\n",
    "            \n",
    "            class_loss = tf.reduce_mean(\n",
    "                keras.losses.binary_crossentropy(data['classes'], reconstruction['classes'])\n",
    "            )\n",
    "            class_loss *= nb_classes\n",
    "\n",
    "            reconstruction_loss = rms_loss + mfcc_loss + rms_cent_loss + zero_crossing_loss \\\n",
    "                                + spectral_centroid_loss + spectral_rolloff_loss+ spectral_contour_loss\n",
    "#             reconstruction_loss = mfcc_loss\n",
    "            reconstruction_loss += class_loss\n",
    "    \n",
    "            kl_loss = 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n",
    "            kl_loss = tf.reduce_mean(kl_loss)\n",
    "            kl_loss *= -0.5\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        return {\n",
    "            \"loss\": total_loss,\n",
    "            \"reconstruction_loss\": reconstruction_loss,\n",
    "            \"kl_loss\": kl_loss,\n",
    "            \"mfcc_loss\": mfcc_loss\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_scaled['classes'] = classes_onehot_df.values\n",
    "encoder = build_encoder()\n",
    "decoder = build_decoder()\n",
    "vae = VAE(encoder, decoder)\n",
    "vae.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001))\n",
    "vae.fit(features_scaled, epochs=20, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "latent_dim = 2\n",
    "input_dim = features.shape[1]\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(input_dim))\n",
    "x = layers.Dense(64, activation=\"relu\")(encoder_inputs)\n",
    "x = layers.Dense(32, activation=\"relu\")(x)\n",
    "x = layers.Dense(32, activation=\"relu\")(x)\n",
    "x = layers.Dense(16, activation=\"relu\")(x)\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\",\n",
    "                         bias_initializer='zeros', kernel_initializer='zeros',\n",
    "                         )(x)\n",
    "                         #activity_regularizer='l1')(x)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "#x = layers.BatchNormalization()(latent_inputs)\n",
    "x = layers.Dense(32, activation=\"relu\")(latent_inputs)\n",
    "x = layers.Dense(32, activation=\"relu\")(x)\n",
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "decoder_outputs = layers.Dense(input_dim, activation=\"relu\")(x)\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def train_step(self, data):\n",
    "        if isinstance(data, tuple):\n",
    "            data = data[0]\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = encoder(data)\n",
    "            reconstruction = decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                keras.losses.MSE(data, reconstruction)\n",
    "            )\n",
    "            reconstruction_loss *= features.shape[1]\n",
    "            kl_loss = 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n",
    "            kl_loss = tf.reduce_mean(kl_loss)\n",
    "            kl_loss *= -0.5\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        return {\n",
    "            \"loss\": total_loss,\n",
    "            \"reconstruction_loss\": reconstruction_loss,\n",
    "            \"kl_loss\": kl_loss,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "vae = VAE(encoder, decoder)\n",
    "vae.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001))\n",
    "vae.fit(features_scaled, epochs=50, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_vae, _, _  = encoder.predict(features_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_vae.shape, class_df['class'].shape, filename.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_vae_df = pd.DataFrame(features_vae, index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dysplay_embedding(\n",
    "    features_vae_df[ 0],\n",
    "    features_vae_df[1],\n",
    "    class_df['class'].values,\n",
    "    filename\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_reducer = umap.UMAP()\n",
    "embedding_vae = vae_reducer.fit_transform(features_vae)\n",
    "#embedding = features_vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dysplay_embedding(\n",
    "    embedding_vae[:, 0],\n",
    "    embedding_vae[:, 1],\n",
    "    class_df['class'].values,\n",
    "    filename\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "decoder_outputs = layers.Dense(nb_classes, activation=\"relu\")(latent_inputs)\n",
    "class_decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "\n",
    "class VAE_class(keras.Model):\n",
    "    def __init__(self, encoder, decoder, class_decoder, **kwargs):\n",
    "        super(VAE_class, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.class_decoder = class_decoder\n",
    "\n",
    "    def train_step(self, data):\n",
    "        if isinstance(data, tuple):\n",
    "            data = data[0]\n",
    "        features, classes = tf.split(data, [nb_features, nb_classes], 1)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(features)\n",
    "            reconstruction = self.decoder(z)\n",
    "            classes_recon = self.class_decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                keras.losses.MSE(features, reconstruction)\n",
    "            )\n",
    "            class_loss = tf.reduce_mean(\n",
    "                keras.losses.MSE(classes, classes_recon)\n",
    "            )\n",
    "            class_loss = class_loss*20\n",
    "            reconstruction_loss *= nb_features/10\n",
    "            class_loss *= nb_classes\n",
    "            kl_loss = 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n",
    "            kl_loss = tf.reduce_mean(kl_loss)\n",
    "            kl_loss *= -0.5\n",
    "            total_loss = reconstruction_loss + kl_loss + class_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        return {\n",
    "            \"loss\": total_loss,\n",
    "            \"reconstruction_loss\": reconstruction_loss,\n",
    "            \"kl_loss\": kl_loss,\n",
    "            \"class_loss\": class_loss,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE_class(encoder, decoder, class_decoder)\n",
    "vae.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001))\n",
    "data = np.concatenate((features_scaled, classes_onehot_df.values), axis=1)\n",
    "vae.fit(data, epochs=50, batch_size=128)\n",
    "\n",
    "features_vae2, _,_  = encoder.predict(features_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_vae_df2 = pd.DataFrame(features_vae2, index=features.index)\n",
    "dysplay_embedding(\n",
    "    features_vae_df2[ 0],\n",
    "    features_vae_df2[1],\n",
    "    class_df['class'].values,\n",
    "    filename\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dysplay_embedding(\n",
    "    features_vae_df[ 0],\n",
    "    features_vae_df[1],\n",
    "    class_df['class'].values,\n",
    "    filename\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
