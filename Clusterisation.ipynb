{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from librosa.core import resample, load\n",
    "from librosa.util import fix_length\n",
    "from librosa import feature\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm as nb_tqdm\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import umap\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "from IPython.display import display\n",
    "import ipywidgets\n",
    "from ipywidgets import Output, VBox\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guillaume/miniconda3/envs/DrumAI/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (4,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('full.csv',index_col=0)\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>filename</th>\n",
       "      <th>dir_1</th>\n",
       "      <th>dir_2</th>\n",
       "      <th>class_Snare</th>\n",
       "      <th>class_Tom</th>\n",
       "      <th>dir_3</th>\n",
       "      <th>class_Cymbal</th>\n",
       "      <th>subclass_Cymbal_Crash</th>\n",
       "      <th>subclass_Cymbal_Ride</th>\n",
       "      <th>...</th>\n",
       "      <th>subclass_Shaken_Cabasa</th>\n",
       "      <th>class_Clave</th>\n",
       "      <th>class_Timpani</th>\n",
       "      <th>class_Agogo</th>\n",
       "      <th>class_Triangle</th>\n",
       "      <th>class_Djembe</th>\n",
       "      <th>class_Tabla</th>\n",
       "      <th>class_Darbuka</th>\n",
       "      <th>subclass_Shaken_Maracas</th>\n",
       "      <th>class_Cajon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./Samples/MDLib2.2/Sorted/Snare SNoff/Buzz/ST_...</td>\n",
       "      <td>ST_Snare_Buzz_0112.2.wav</td>\n",
       "      <td>Buzz</td>\n",
       "      <td>Snare SNoff</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./Samples/MDLib2.2/Sorted/Snare SNoff/Buzz/DI_...</td>\n",
       "      <td>DI_Snare_Buzz_0224.3.wav</td>\n",
       "      <td>Buzz</td>\n",
       "      <td>Snare SNoff</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./Samples/MDLib2.2/Sorted/Snare SNoff/Buzz/IN_...</td>\n",
       "      <td>IN_Snare_Buzz_0214.1.wav</td>\n",
       "      <td>Buzz</td>\n",
       "      <td>Snare SNoff</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./Samples/MDLib2.2/Sorted/Snare SNoff/Buzz/ST_...</td>\n",
       "      <td>ST_Snare_Buzz_0333.3.wav</td>\n",
       "      <td>Buzz</td>\n",
       "      <td>Snare SNoff</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./Samples/MDLib2.2/Sorted/Snare SNoff/Buzz/MN_...</td>\n",
       "      <td>MN_Snare_Buzz_0111.4.wav</td>\n",
       "      <td>Buzz</td>\n",
       "      <td>Snare SNoff</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>./Samples/MDLib2.2/Sorted/Snare SNoff/Buzz/IN_...</td>\n",
       "      <td>IN_Snare_Buzz_0112.3.wav</td>\n",
       "      <td>Buzz</td>\n",
       "      <td>Snare SNoff</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>./Samples/MDLib2.2/Sorted/Snare SNoff/Buzz/DI_...</td>\n",
       "      <td>DI_Snare_Buzz_0322.1.wav</td>\n",
       "      <td>Buzz</td>\n",
       "      <td>Snare SNoff</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>./Samples/MDLib2.2/Sorted/Snare SNoff/Buzz/MN_...</td>\n",
       "      <td>MN_Snare_Buzz_0321.2.wav</td>\n",
       "      <td>Buzz</td>\n",
       "      <td>Snare SNoff</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>./Samples/MDLib2.2/Sorted/Snare SNoff/Buzz/MN_...</td>\n",
       "      <td>MN_Snare_Buzz_0231.2.wav</td>\n",
       "      <td>Buzz</td>\n",
       "      <td>Snare SNoff</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>./Samples/MDLib2.2/Sorted/Snare SNoff/Buzz/ST_...</td>\n",
       "      <td>ST_Snare_Buzz_0232.4.wav</td>\n",
       "      <td>Buzz</td>\n",
       "      <td>Snare SNoff</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  \\\n",
       "0  ./Samples/MDLib2.2/Sorted/Snare SNoff/Buzz/ST_...   \n",
       "1  ./Samples/MDLib2.2/Sorted/Snare SNoff/Buzz/DI_...   \n",
       "2  ./Samples/MDLib2.2/Sorted/Snare SNoff/Buzz/IN_...   \n",
       "3  ./Samples/MDLib2.2/Sorted/Snare SNoff/Buzz/ST_...   \n",
       "4  ./Samples/MDLib2.2/Sorted/Snare SNoff/Buzz/MN_...   \n",
       "5  ./Samples/MDLib2.2/Sorted/Snare SNoff/Buzz/IN_...   \n",
       "6  ./Samples/MDLib2.2/Sorted/Snare SNoff/Buzz/DI_...   \n",
       "7  ./Samples/MDLib2.2/Sorted/Snare SNoff/Buzz/MN_...   \n",
       "8  ./Samples/MDLib2.2/Sorted/Snare SNoff/Buzz/MN_...   \n",
       "9  ./Samples/MDLib2.2/Sorted/Snare SNoff/Buzz/ST_...   \n",
       "\n",
       "                   filename dir_1        dir_2  class_Snare  class_Tom dir_3  \\\n",
       "0  ST_Snare_Buzz_0112.2.wav  Buzz  Snare SNoff          1.0        0.0     0   \n",
       "1  DI_Snare_Buzz_0224.3.wav  Buzz  Snare SNoff          1.0        0.0     0   \n",
       "2  IN_Snare_Buzz_0214.1.wav  Buzz  Snare SNoff          1.0        0.0     0   \n",
       "3  ST_Snare_Buzz_0333.3.wav  Buzz  Snare SNoff          1.0        0.0     0   \n",
       "4  MN_Snare_Buzz_0111.4.wav  Buzz  Snare SNoff          1.0        0.0     0   \n",
       "5  IN_Snare_Buzz_0112.3.wav  Buzz  Snare SNoff          1.0        0.0     0   \n",
       "6  DI_Snare_Buzz_0322.1.wav  Buzz  Snare SNoff          1.0        0.0     0   \n",
       "7  MN_Snare_Buzz_0321.2.wav  Buzz  Snare SNoff          1.0        0.0     0   \n",
       "8  MN_Snare_Buzz_0231.2.wav  Buzz  Snare SNoff          1.0        0.0     0   \n",
       "9  ST_Snare_Buzz_0232.4.wav  Buzz  Snare SNoff          1.0        0.0     0   \n",
       "\n",
       "   class_Cymbal  subclass_Cymbal_Crash  subclass_Cymbal_Ride  ...  \\\n",
       "0           0.0                    0.0                   0.0  ...   \n",
       "1           0.0                    0.0                   0.0  ...   \n",
       "2           0.0                    0.0                   0.0  ...   \n",
       "3           0.0                    0.0                   0.0  ...   \n",
       "4           0.0                    0.0                   0.0  ...   \n",
       "5           0.0                    0.0                   0.0  ...   \n",
       "6           0.0                    0.0                   0.0  ...   \n",
       "7           0.0                    0.0                   0.0  ...   \n",
       "8           0.0                    0.0                   0.0  ...   \n",
       "9           0.0                    0.0                   0.0  ...   \n",
       "\n",
       "   subclass_Shaken_Cabasa  class_Clave  class_Timpani  class_Agogo  \\\n",
       "0                     0.0          0.0            0.0          0.0   \n",
       "1                     0.0          0.0            0.0          0.0   \n",
       "2                     0.0          0.0            0.0          0.0   \n",
       "3                     0.0          0.0            0.0          0.0   \n",
       "4                     0.0          0.0            0.0          0.0   \n",
       "5                     0.0          0.0            0.0          0.0   \n",
       "6                     0.0          0.0            0.0          0.0   \n",
       "7                     0.0          0.0            0.0          0.0   \n",
       "8                     0.0          0.0            0.0          0.0   \n",
       "9                     0.0          0.0            0.0          0.0   \n",
       "\n",
       "   class_Triangle  class_Djembe  class_Tabla  class_Darbuka  \\\n",
       "0             0.0           0.0          0.0            0.0   \n",
       "1             0.0           0.0          0.0            0.0   \n",
       "2             0.0           0.0          0.0            0.0   \n",
       "3             0.0           0.0          0.0            0.0   \n",
       "4             0.0           0.0          0.0            0.0   \n",
       "5             0.0           0.0          0.0            0.0   \n",
       "6             0.0           0.0          0.0            0.0   \n",
       "7             0.0           0.0          0.0            0.0   \n",
       "8             0.0           0.0          0.0            0.0   \n",
       "9             0.0           0.0          0.0            0.0   \n",
       "\n",
       "   subclass_Shaken_Maracas  class_Cajon  \n",
       "0                      0.0          0.0  \n",
       "1                      0.0          0.0  \n",
       "2                      0.0          0.0  \n",
       "3                      0.0          0.0  \n",
       "4                      0.0          0.0  \n",
       "5                      0.0          0.0  \n",
       "6                      0.0          0.0  \n",
       "7                      0.0          0.0  \n",
       "8                      0.0          0.0  \n",
       "9                      0.0          0.0  \n",
       "\n",
       "[10 rows x 35 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20869/20869 [28:08<00:00, 12.36it/s] \n"
     ]
    }
   ],
   "source": [
    "SR=22050\n",
    "rms_list = []\n",
    "rms_cent_list = []\n",
    "zero_cross_list = []\n",
    "spect_cent_list = []\n",
    "spect_ro_list = []\n",
    "spect_cont_list = []\n",
    "mfcc_list = []\n",
    "index_list = []\n",
    "#data = data.sample(frac=0.2)\n",
    "for index, file in tqdm(zip(df.index, df['path']), total=len(df.index), position=0, leave=True):\n",
    "    try:\n",
    "        sound, _ = load(file, sr=SR)\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    index_list.append(index)\n",
    "    \n",
    "    rms = feature.rms(sound)[0]\n",
    "     #normalize by rms of attack frame\n",
    "    rms_centroid = (rms * np.arange(len(rms))).sum() / rms.sum()\n",
    "#     features.loc[index, 'rms_centroid'] = rms_centroid\n",
    "    rms_cent_list.append(rms_centroid)\n",
    "    \n",
    "    sound = sound/rms.max()\n",
    "    sound = fix_length(sound, 1024*(SR//1024))\n",
    "    \n",
    "    zero_cr = feature.zero_crossing_rate(sound)[0]\n",
    "#     columns = ['zero_cr_' + str(x) for x in range(zero_cr.shape[0])]\n",
    "#     for col, value in zip(columns, zero_cr):\n",
    "#         features.loc[index, col] = value\n",
    "    zero_cross_list.append(zero_cr)\n",
    "        \n",
    "    spect_cent = feature.spectral_centroid(sound, sr=SR)[0]\n",
    "#     columns = ['spect_cent_' + str(x) for x in range(spect_cent.shape[0])]\n",
    "#     for col, value in zip(columns, spect_cent):\n",
    "#         features.loc[index, col] = value\n",
    "    spect_cent_list.append(spect_cent)\n",
    "        \n",
    "    spect_ro = feature.spectral_rolloff(sound, sr=SR)[0]\n",
    "#     columns = ['spect_ro_' + str(x) for x in range(spect_ro.shape[0])]\n",
    "#     for col, value in zip(columns, spect_ro):\n",
    "#         features.loc[index, col] = value\n",
    "    spect_ro_list.append(spect_ro)\n",
    "        \n",
    "    rms = feature.rms(sound)[0]\n",
    "#     columns = ['rms_' + str(x) for x in range(rms.shape[0])]\n",
    "#     for col, value in zip(columns, rms):\n",
    "#         #features.loc[index, col] = value\n",
    "#         features.loc[index, 'norm_'+ col] = value\n",
    "    rms_list.append(rms)\n",
    "    \n",
    "        \n",
    "    spect_cont = feature.spectral_contrast(sound, sr=SR)\n",
    "#     for i in range (spect_cont.shape[0]):\n",
    "#         for j in range (spect_cont.shape[1]):\n",
    "#             col = 'spec_cont_' + str(i) + '_' + str(j)\n",
    "#             features.loc[index, col] = spect_cont[i][j]\n",
    "    spect_cont_list.append(spect_cont)\n",
    "    \n",
    "    mfcc = feature.mfcc(sound, sr=SR)\n",
    "    mfcc_list.append(mfcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "rms = np.stack(rms_list)\n",
    "rms_cent = np.stack(rms_cent_list)\n",
    "zero_cross = np.stack(zero_cross_list)\n",
    "spect_cent = np.stack(spect_cent_list)\n",
    "spect_ro = np.stack(spect_ro_list)\n",
    "spect_cont = np.stack(spect_cont_list)\n",
    "mfcc = np.stack(mfcc_list)\n",
    "index = np.stack(index_list)\n",
    "\n",
    "np.save('feature_rms.npy', rms)\n",
    "np.save('feature_rms_centroid.npy', rms_cent)\n",
    "np.save('feature_zero_crossing_rate.npy', zero_cross)\n",
    "np.save('feature_spectral_centroid.npy', spect_cent)\n",
    "np.save('feature_spectral_rolloff.npy', spect_ro)\n",
    "np.save('feature_spectral_contour.npy', spect_cont)\n",
    "np.save('feature_mfcc.npy', mfcc)\n",
    "np.save('index.npy', index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms = np.load('feature_rms.npy')\n",
    "rms_cent = np.load('feature_rms_centroid.npy')\n",
    "zero_cross = np.load('feature_zero_crossing_rate.npy')\n",
    "spect_cent = np.load('feature_spectral_centroid.npy')\n",
    "spect_ro = np.load('feature_spectral_rolloff.npy')\n",
    "spect_cont = np.load('feature_spectral_contour.npy')\n",
    "mfcc = np.load('feature_mfcc.npy')\n",
    "index = np.load('index.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20869,)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20869, 474)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = index.shape[0]\n",
    "features = np.hstack([\n",
    "    rms.reshape(size,-1),\n",
    "    rms_cent.reshape(size,-1),\n",
    "    zero_cross.reshape(size,-1),\n",
    "    spect_cent.reshape(size,-1),\n",
    "    spect_ro.reshape(size,-1),\n",
    "    spect_cont.reshape(size,-1),\n",
    "                  ])\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "features.to_csv('features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv('features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['path', 'filename', 'dir_1', 'dir_2', 'class_Snare', 'class_Tom',\n",
       "       'dir_3', 'class_Cymbal', 'subclass_Cymbal_Crash',\n",
       "       'subclass_Cymbal_Ride', 'class_Hat', 'class_Kick', 'subclass_Hat_Open',\n",
       "       'subclass_Hat_Close', 'class_Bongo', 'subclass_Cymbal_Chinese',\n",
       "       'subclass_Cymbal_Splash', 'class_Conga', 'class_Gong', 'class_Cowbell',\n",
       "       'class_Rimshot', 'class_Clap', 'class_Shaken', 'subclass_Shaken_Shaker',\n",
       "       'subclass_Shaken_Tambourin', 'subclass_Shaken_Cabasa', 'class_Clave',\n",
       "       'class_Timpani', 'class_Agogo', 'class_Triangle', 'class_Djembe',\n",
       "       'class_Tabla', 'class_Darbuka', 'subclass_Shaken_Maracas',\n",
       "       'class_Cajon'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [c for c in df.columns if c.startswith('class_')]\n",
    "cymb_classes = [c for c in df.columns if c.startswith('subclass_Cymbal')]\n",
    "shak_classes = [c for c in df.columns if c.startswith('subclass_Shaken')]\n",
    "hat_classes = [c for c in df.columns if c.startswith('subclass_Hat')]\n",
    "\n",
    "all_classes = classes + cymb_classes + shak_classes + hat_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['subclass_Cymbal_Crash',\n",
       " 'subclass_Cymbal_Ride',\n",
       " 'subclass_Cymbal_Chinese',\n",
       " 'subclass_Cymbal_Splash']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cymb_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_df = pd.DataFrame()\n",
    "\n",
    "class_df['class'] = df[all_classes].idxmax(axis=1)\n",
    "\n",
    "mask = df[all_classes].sum(axis=1) == 0\n",
    "class_df.loc[mask, 'class'] = 'Error'\n",
    "\n",
    "cymbales = (df['class_Cymbal'] == 1) & (df[cymb_classes].sum(axis=1) > 0)\n",
    "class_df.loc[cymbales, 'class'] = df.loc[cymbales, cymb_classes].idxmax(axis=1)\n",
    "\n",
    "shaken = (df['class_Shaken'] == 1) & (df[shak_classes].sum(axis=1) > 0)\n",
    "class_df.loc[shaken, 'class'] = df.loc[shaken, shak_classes].idxmax(axis=1)\n",
    "\n",
    "hats = (df['class_Hat'] == 1) & (df[hat_classes].sum(axis=1) > 0)\n",
    "class_df.loc[hats, 'class'] = df.loc[hats, hat_classes].idxmax(axis=1)\n",
    "# class_df['class'] = df[hat_classes + ['class_Hat']].idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10639       subclass_Shaken_Shaker\n",
       "10703       subclass_Shaken_Shaker\n",
       "10736    subclass_Shaken_Tambourin\n",
       "10763    subclass_Shaken_Tambourin\n",
       "10795       subclass_Shaken_Cabasa\n",
       "                   ...            \n",
       "20776    subclass_Shaken_Tambourin\n",
       "20777       subclass_Shaken_Shaker\n",
       "20779      subclass_Shaken_Maracas\n",
       "20853    subclass_Shaken_Tambourin\n",
       "20863    subclass_Shaken_Tambourin\n",
       "Length: 140, dtype: object"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[shaken, shak_classes].idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7488</th>\n",
       "      <td>subclass_Cymbal_Crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7489</th>\n",
       "      <td>subclass_Cymbal_Crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7490</th>\n",
       "      <td>subclass_Cymbal_Crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7491</th>\n",
       "      <td>subclass_Cymbal_Crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7492</th>\n",
       "      <td>subclass_Cymbal_Crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20852</th>\n",
       "      <td>subclass_Hat_Close</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20853</th>\n",
       "      <td>subclass_Shaken_Tambourin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20855</th>\n",
       "      <td>subclass_Hat_Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20859</th>\n",
       "      <td>subclass_Hat_Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20863</th>\n",
       "      <td>subclass_Shaken_Tambourin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1917 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           class\n",
       "7488       subclass_Cymbal_Crash\n",
       "7489       subclass_Cymbal_Crash\n",
       "7490       subclass_Cymbal_Crash\n",
       "7491       subclass_Cymbal_Crash\n",
       "7492       subclass_Cymbal_Crash\n",
       "...                          ...\n",
       "20852         subclass_Hat_Close\n",
       "20853  subclass_Shaken_Tambourin\n",
       "20855          subclass_Hat_Open\n",
       "20859          subclass_Hat_Open\n",
       "20863  subclass_Shaken_Tambourin\n",
       "\n",
       "[1917 rows x 1 columns]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_df[class_df['class'].str.startswith('subclass_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dysplay_embedding(x, y, classes, files):\n",
    "    embedding_vae_df = pd.DataFrame({\n",
    "        'x': x,\n",
    "        'y': y,\n",
    "        'class': classes,\n",
    "        'file': files    \n",
    "                         })\n",
    "    \n",
    "    scatter = px.scatter(\n",
    "        embedding_vae_df,\n",
    "        x='x',\n",
    "        y='y',\n",
    "        color='class',\n",
    "        hover_data=['file']\n",
    "    )\n",
    "    figure = go.FigureWidget(scatter)\n",
    "\n",
    "    out = Output()\n",
    "\n",
    "    @out.capture(clear_output=False, wait=True)\n",
    "    def play_sound(trace, points, selector):\n",
    "        if len(points.point_inds) != 1:\n",
    "           return\n",
    "        #print(points)\n",
    "        out.clear_output()\n",
    "        path = trace.customdata[points.point_inds[0]][0]\n",
    "        #print(path)\n",
    "        sound, sr = load(path)\n",
    "        IPython.display.display(IPython.display.Audio(sound, rate=sr, autoplay=True))\n",
    "\n",
    "    for trace in figure.data:\n",
    "        trace.on_click(play_sound)\n",
    "\n",
    "\n",
    "    box = VBox([figure, out])\n",
    "    display(box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler \n",
    "# scaler = StandardScaler()\n",
    "# features_scaled = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = umap.UMAP()\n",
    "embedding = reducer.fit_transform(features_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20869, 1)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_df = class_df.loc[index]\n",
    "class_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = df.loc[index,'path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guillaume/.local/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning:\n",
      "\n",
      "\n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classes_onehot_df = df[all_classes]\n",
    "classes_onehot_df = classes_onehot_df.loc[features.index]\n",
    "nb_classes =  classes_onehot_df.shape[1]\n",
    "nb_features = features.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f3d6bf83b844022b325be4a556d56d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(FigureWidget({\n",
       "    'data': [{'customdata': array([['./Samples/MDLib2.2/Sorted/Snare SNoff/Buzz/…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dysplay_embedding(\n",
    "    embedding[:, 0],\n",
    "    embedding[:, 1],\n",
    "    class_df['class'].values,\n",
    "    filename\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rms_cent = rms_cent.reshape(-1, 1)\n",
    "# rms = rms.reshape(-1,rms.shape[1], 1)\n",
    "features_input = dict(\n",
    "    rms=rms,\n",
    "    rms_centroid=rms_cent,\n",
    "    zero_crossing=zero_cross,\n",
    "    spectral_centroid=spect_cent,\n",
    "    spectral_rolloff=spect_ro,\n",
    "    spectral_contour=spect_cont,\n",
    "    mfcc=mfcc\n",
    ")\n",
    "for key, feature in list(features_input.items()):\n",
    "    if feature.shape[-1] !=1:\n",
    "        features_input[key] = np.expand_dims(feature, axis=feature.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = {}\n",
    "features_scaled = {}\n",
    "for key, feature in list(features_input.items()):\n",
    "    scaler[key] = {}\n",
    "    scaler[key]['max'] = max(feature.max(), -feature.min())\n",
    "    features_scaled[key] = feature/scaler[key]['max']\n",
    "#     scaler[key]['mean'] = feature.mean()\n",
    "# #     scaler[key]['mean'] = feature.mean(axis=0)\n",
    "#     f = feature-scaler[key]['mean']\n",
    "#     scaler[key]['std'] = f.std()\n",
    "# #     scaler[key]['std'] = f.std(axis=0)\n",
    "#     features_scaled[key] = f/scaler[key]['std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rms 0.0 1.0\n",
      "rms_centroid 0.0 1.0\n",
      "zero_crossing 0.0 1.0\n",
      "spectral_centroid 0.0 1.0\n",
      "spectral_rolloff 0.0 1.0\n",
      "spectral_contour 0.0 1.0\n",
      "mfcc -1.0 0.3804038\n"
     ]
    }
   ],
   "source": [
    "for key, feature in list(features_scaled.items()):\n",
    "    print(key, feature.min(), feature.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rms shape: (43, 1)\n",
      "rms_centroid shape: (1,)\n",
      "zero_crossing shape: (43, 1)\n",
      "spectral_centroid shape: (43, 1)\n",
      "spectral_rolloff shape: (43, 1)\n",
      "spectral_contour shape: (7, 43, 1)\n",
      "mfcc shape: (20, 43, 1)\n"
     ]
    }
   ],
   "source": [
    "for key, value in features_scaled.items():\n",
    "    print(f\"{key} shape: {value.shape[1:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim=2\n",
    "def build_encoder():\n",
    "    rms_input = keras.Input(shape=features_input['rms'].shape[1:])\n",
    "    rms_cent_input = keras.Input(shape=features_input['rms_centroid'].shape[1:])\n",
    "    zero_cross_input = keras.Input(shape=features_input['zero_crossing'].shape[1:])\n",
    "    spect_cent_input = keras.Input(shape=features_input['spectral_centroid'].shape[1:])\n",
    "    spect_ro_input = keras.Input(shape=features_input['spectral_rolloff'].shape[1:])\n",
    "    spect_cont_input = keras.Input(shape=features_input['spectral_contour'].shape[1:])\n",
    "    mfcc_input = keras.Input(shape=features_input['mfcc'].shape[1:])\n",
    "\n",
    "    x=rms_input\n",
    "    for filters in [4,8,16]:\n",
    "        x = layers.Conv1D(filters,3,activation='relu',padding='same')(x)\n",
    "        x = layers.MaxPooling1D(2)(x)\n",
    "    rms_out = layers.Flatten()(x)\n",
    "\n",
    "    x=zero_cross_input\n",
    "    for filters in [4,8,16]:\n",
    "        x = layers.Conv1D(filters,3,activation='relu',padding='same')(x)\n",
    "        x = layers.MaxPooling1D(2)(x)\n",
    "    zero_cross_out = layers.Flatten()(x)\n",
    "\n",
    "    x=spect_cent_input\n",
    "    for filters in [4,8,16]:\n",
    "        x = layers.Conv1D(filters,3,activation='relu',padding='same')(x)\n",
    "        x = layers.MaxPooling1D(2)(x)\n",
    "    spect_cent_out = layers.Flatten()(x)\n",
    "\n",
    "    x=spect_ro_input\n",
    "    for filters in [4,8,16]:\n",
    "        x = layers.Conv1D(filters,3,activation='relu',padding='same')(x)\n",
    "        x = layers.MaxPooling1D(2)(x)\n",
    "    spect_ro_out = layers.Flatten()(x)\n",
    "\n",
    "    x=mfcc_input\n",
    "    for filters in [8,16,32]:\n",
    "        x = layers.Conv2D(filters, (3,3), activation='tanh',padding='same')(x)\n",
    "        x = layers.MaxPooling2D((2,2))(x)\n",
    "    x = layers.MaxPooling2D((2,1))(x)\n",
    "    mfcc_out = layers.Flatten()(x)\n",
    "\n",
    "    x=spect_cont_input\n",
    "    for filters in [4,8]:\n",
    "        x = layers.Conv2D(filters, (3,3), activation='relu',padding='same')(x)\n",
    "        x = layers.MaxPooling2D((2,2))(x)\n",
    "    x = layers.Conv2D(16, (3,3), activation='relu',padding='same')(x)\n",
    "    x = layers.MaxPooling2D((1,2))(x)\n",
    "    spect_cont_out = layers.Flatten()(x)\n",
    "\n",
    "    concat = layers.Concatenate()((rms_cent_input, rms_out, zero_cross_out, spect_cent_out,\n",
    "                              spect_ro_out, mfcc_out, spect_cont_out))\n",
    "\n",
    "    x= concat\n",
    "    for size in [32, 16, 8]:\n",
    "        x = layers.Dense(size, activation='relu')(x)\n",
    "    z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "    z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "    z = Sampling()([z_mean, z_log_var])\n",
    "\n",
    "    inputs = dict(\n",
    "        rms=rms_input,\n",
    "        rms_centroid=rms_cent_input,\n",
    "        zero_crossing=zero_cross_input,\n",
    "        spectral_centroid=spect_cent_input,\n",
    "        spectral_rolloff=spect_ro_input,\n",
    "        spectral_contour=spect_cont_input,\n",
    "        mfcc=mfcc_input,\n",
    "    )\n",
    "    outputs =  (z_mean, z_log_var, z)\n",
    "\n",
    "    encoder = keras.Model(inputs, outputs, name=\"encoder\")\n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_decoder():\n",
    "    latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "\n",
    "    x = layers.Dense(1 * 6 * 16, activation=\"relu\")(latent_inputs)\n",
    "    x = layers.Reshape((1, 6, 16))(x)\n",
    "    x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=(2,2), padding=\"same\")(x)\n",
    "    x = layers.Conv2DTranspose(16, 3, activation=\"relu\", strides=(2,2), padding=\"same\")(x)\n",
    "    x = layers.Conv2DTranspose(1, 3, activation=\"sigmoid\", strides=(2,2), padding=\"same\")(x)\n",
    "    x = layers.Cropping2D(cropping=((0,1),(2,3)))(x)\n",
    "    spect_cont_out = x\n",
    "\n",
    "    x = layers.Dense(16, activation=\"relu\")(latent_inputs)\n",
    "    x = layers.Dense(3 * 6 * 16, activation=\"relu\")(x)\n",
    "    x = layers.Reshape((3, 6, 16))(x)\n",
    "    x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=(2,2), padding=\"same\")(x)\n",
    "    x = layers.Conv2DTranspose(16, 3, activation=\"relu\", strides=(2,2), padding=\"same\")(x)\n",
    "    x = layers.Conv2DTranspose(1, 3, activation=\"tanh\", strides=(2,2), padding=\"same\")(x)\n",
    "    x = layers.Cropping2D(cropping=((2,2),(2,3)))(x)\n",
    "    mfcc_out = x\n",
    "\n",
    "    # x = layers.Dense(16, activation=\"relu\")(latent_inputs)\n",
    "    # x = layers.Dense(32, activation=\"relu\")(x)\n",
    "    # x = layers.Dense(64, activation=\"relu\")(x)\n",
    "    # x = layers.Dense(20*43, activation=\"relu\")(x)\n",
    "    # mfcc_out = layers.Reshape((20, 43, 1))(x)\n",
    "\n",
    "    x = layers.Dense(6 * 16, activation=\"relu\")(latent_inputs)\n",
    "    x = layers.Reshape((6, 16))(x)\n",
    "    x = layers.Conv1DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "    x = layers.Conv1DTranspose(16, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "    x = layers.Conv1DTranspose(1, 3, activation=\"sigmoid\", strides=2, padding=\"same\")(x)\n",
    "    x = layers.Cropping1D(cropping=(2,3))(x)\n",
    "    rms_out = x\n",
    "\n",
    "    x = layers.Dense(6 * 16, activation=\"relu\")(latent_inputs)\n",
    "    x = layers.Reshape((6, 16))(x)\n",
    "    x = layers.Conv1DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "    x = layers.Conv1DTranspose(16, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "    x = layers.Conv1DTranspose(1, 3, activation=\"sigmoid\", strides=2, padding=\"same\")(x)\n",
    "    x = layers.Cropping1D(cropping=(2,3))(x)\n",
    "    zero_cross_out = x\n",
    "\n",
    "    x = layers.Dense(6 * 16, activation=\"relu\")(latent_inputs)\n",
    "    x = layers.Reshape((6, 16))(x)\n",
    "    x = layers.Conv1DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "    x = layers.Conv1DTranspose(16, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "    x = layers.Conv1DTranspose(1, 3, activation=\"sigmoid\", strides=2, padding=\"same\")(x)\n",
    "    x = layers.Cropping1D(cropping=(2,3))(x)\n",
    "    spect_cent_out = x\n",
    "\n",
    "    x = layers.Dense(6 * 16, activation=\"relu\")(latent_inputs)\n",
    "    x = layers.Reshape((6, 16))(x)\n",
    "    x = layers.Conv1DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "    x = layers.Conv1DTranspose(16, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "    x = layers.Conv1DTranspose(1, 3, activation=\"sigmoid\", strides=2, padding=\"same\")(x)\n",
    "    x = layers.Cropping1D(cropping=(2,3))(x)\n",
    "    spect_ro_out = x\n",
    "\n",
    "    for size in (4,8,16):\n",
    "        x = layers.Dense(size, activation=\"relu\")(latent_inputs)\n",
    "    rms_cent_out = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    x = layers.Dense(8, activation=\"sigmoid\")(latent_inputs)\n",
    "    class_out = layers.Dense(nb_classes, activation=\"sigmoid\")(x)\n",
    "\n",
    "    outputs = dict(\n",
    "        rms=rms_out,\n",
    "        rms_centroid=rms_cent_out,\n",
    "        zero_crossing=zero_cross_out,\n",
    "        spectral_centroid=spect_cent_out,\n",
    "        spectral_rolloff=spect_ro_out,\n",
    "        spectral_contour=spect_cont_out,\n",
    "        mfcc=mfcc_out,\n",
    "        classes=class_out\n",
    "    )\n",
    "    decoder_outputs = x\n",
    "    #decoder_outputs = layers.Dense(input_dim, activation=\"relu\")(x)\n",
    "    decoder = keras.Model(latent_inputs, outputs, name=\"decoder\")\n",
    "    return decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def train_step(self, data):\n",
    "        if isinstance(data, tuple):\n",
    "            data = data[0]\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = encoder(data)\n",
    "            reconstruction = decoder(z)\n",
    "            \n",
    "            rms_loss = tf.reduce_mean(\n",
    "                keras.losses.binary_crossentropy(data['rms'], reconstruction['rms'])\n",
    "            )\n",
    "            rms_loss *= 43\n",
    "            zero_crossing_loss = tf.reduce_mean(\n",
    "                keras.losses.binary_crossentropy(data['zero_crossing'], reconstruction['zero_crossing'])\n",
    "            )\n",
    "            zero_crossing_loss *= 43\n",
    "            spectral_centroid_loss = tf.reduce_mean(\n",
    "                keras.losses.binary_crossentropy(data['spectral_centroid'], reconstruction['spectral_centroid'])\n",
    "            )\n",
    "            spectral_centroid_loss *= 43\n",
    "            spectral_rolloff_loss = tf.reduce_mean(\n",
    "                keras.losses.binary_crossentropy(data['spectral_rolloff'], reconstruction['spectral_rolloff'])\n",
    "            )\n",
    "            spectral_rolloff_loss *= 43\n",
    "            mfcc_loss = tf.reduce_mean(\n",
    "                keras.losses.MSE(data['mfcc'], reconstruction['mfcc'])\n",
    "            )\n",
    "            mfcc_loss *= 20*43\n",
    "            spectral_contour_loss = tf.reduce_mean(\n",
    "                keras.losses.MSE(data['spectral_contour'], reconstruction['spectral_contour'])\n",
    "            )\n",
    "            spectral_contour_loss *= 7*43\n",
    "            rms_cent_loss = tf.reduce_mean(\n",
    "                keras.losses.binary_crossentropy(data['rms_centroid'], reconstruction['rms_centroid'])\n",
    "            )\n",
    "            \n",
    "            class_loss = tf.reduce_mean(\n",
    "                keras.losses.binary_crossentropy(data['classes'], reconstruction['classes'])\n",
    "            )\n",
    "            class_loss *= nb_classes\n",
    "\n",
    "            reconstruction_loss = rms_loss + mfcc_loss + rms_cent_loss + zero_crossing_loss \\\n",
    "                                + spectral_centroid_loss + spectral_rolloff_loss+ spectral_contour_loss\n",
    "#             reconstruction_loss = mfcc_loss\n",
    "#             reconstruction_loss += class_loss\n",
    "    \n",
    "            kl_loss = 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n",
    "            kl_loss = tf.reduce_mean(kl_loss)\n",
    "            kl_loss *= -0.5\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        return {\n",
    "            \"loss\": total_loss,\n",
    "            \"reconstruction_loss\": reconstruction_loss,\n",
    "            \"kl_loss\": kl_loss,\n",
    "            \"mfcc_loss\": mfcc_loss\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_296/kernel:0', 'dense_296/bias:0', 'dense_297/kernel:0', 'dense_297/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_296/kernel:0', 'dense_296/bias:0', 'dense_297/kernel:0', 'dense_297/bias:0'] when minimizing the loss.\n",
      "164/164 [==============================] - 7s 44ms/step - loss: 95.8717 - reconstruction_loss: 94.4848 - kl_loss: 1.3869 - mfcc_loss: 2.7889\n",
      "Epoch 2/20\n",
      "164/164 [==============================] - 7s 44ms/step - loss: 66.8620 - reconstruction_loss: 65.0746 - kl_loss: 1.7873 - mfcc_loss: 1.0783\n",
      "Epoch 3/20\n",
      "164/164 [==============================] - 7s 45ms/step - loss: 62.9466 - reconstruction_loss: 60.9209 - kl_loss: 2.0258 - mfcc_loss: 0.8433\n",
      "Epoch 4/20\n",
      "164/164 [==============================] - 7s 44ms/step - loss: 60.8340 - reconstruction_loss: 58.6708 - kl_loss: 2.1631 - mfcc_loss: 0.7729\n",
      "Epoch 5/20\n",
      "164/164 [==============================] - 7s 45ms/step - loss: 59.8992 - reconstruction_loss: 57.6976 - kl_loss: 2.2016 - mfcc_loss: 0.7231\n",
      "Epoch 6/20\n",
      "164/164 [==============================] - 7s 45ms/step - loss: 59.8135 - reconstruction_loss: 57.6115 - kl_loss: 2.2020 - mfcc_loss: 0.6990\n",
      "Epoch 7/20\n",
      "164/164 [==============================] - 8s 47ms/step - loss: 59.4774 - reconstruction_loss: 57.2748 - kl_loss: 2.2025 - mfcc_loss: 0.6791\n",
      "Epoch 8/20\n",
      "164/164 [==============================] - 8s 47ms/step - loss: 59.0520 - reconstruction_loss: 56.8334 - kl_loss: 2.2186 - mfcc_loss: 0.6620\n",
      "Epoch 9/20\n",
      "164/164 [==============================] - 8s 47ms/step - loss: 58.8247 - reconstruction_loss: 56.6109 - kl_loss: 2.2138 - mfcc_loss: 0.6477\n",
      "Epoch 10/20\n",
      "164/164 [==============================] - 8s 47ms/step - loss: 58.5406 - reconstruction_loss: 56.3149 - kl_loss: 2.2257 - mfcc_loss: 0.6391\n",
      "Epoch 11/20\n",
      "164/164 [==============================] - 8s 47ms/step - loss: 58.4128 - reconstruction_loss: 56.1794 - kl_loss: 2.2334 - mfcc_loss: 0.6289\n",
      "Epoch 12/20\n",
      "164/164 [==============================] - 8s 47ms/step - loss: 58.5064 - reconstruction_loss: 56.2588 - kl_loss: 2.2476 - mfcc_loss: 0.6176: 2s - loss: 58.4519 - reconstruction_loss: 56.2046 - kl\n",
      "Epoch 13/20\n",
      "164/164 [==============================] - 8s 48ms/step - loss: 58.0178 - reconstruction_loss: 55.7600 - kl_loss: 2.2578 - mfcc_loss: 0.6128\n",
      "Epoch 14/20\n",
      "164/164 [==============================] - 8s 50ms/step - loss: 58.2284 - reconstruction_loss: 55.9760 - kl_loss: 2.2524 - mfcc_loss: 0.6112\n",
      "Epoch 15/20\n",
      "164/164 [==============================] - 9s 53ms/step - loss: 58.4499 - reconstruction_loss: 56.1735 - kl_loss: 2.2765 - mfcc_loss: 0.6056\n",
      "Epoch 16/20\n",
      "164/164 [==============================] - 7s 45ms/step - loss: 58.1164 - reconstruction_loss: 55.8338 - kl_loss: 2.2826 - mfcc_loss: 0.5989\n",
      "Epoch 17/20\n",
      "164/164 [==============================] - 9s 52ms/step - loss: 58.2939 - reconstruction_loss: 56.0058 - kl_loss: 2.2880 - mfcc_loss: 0.6045\n",
      "Epoch 18/20\n",
      "164/164 [==============================] - 8s 50ms/step - loss: 58.0779 - reconstruction_loss: 55.7942 - kl_loss: 2.2837 - mfcc_loss: 0.6001\n",
      "Epoch 19/20\n",
      "164/164 [==============================] - 8s 49ms/step - loss: 57.8621 - reconstruction_loss: 55.5694 - kl_loss: 2.2927 - mfcc_loss: 0.5914\n",
      "Epoch 20/20\n",
      "164/164 [==============================] - 8s 48ms/step - loss: 57.9028 - reconstruction_loss: 55.6010 - kl_loss: 2.3018 - mfcc_loss: 0.5856\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f36780e8810>"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_scaled['classes'] = classes_onehot_df.values\n",
    "encoder = build_encoder()\n",
    "decoder = build_decoder()\n",
    "vae = VAE(encoder, decoder)\n",
    "vae.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001))\n",
    "vae.fit(features_scaled, epochs=20, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "latent_dim = 2\n",
    "input_dim = features.shape[1]\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(input_dim))\n",
    "x = layers.Dense(64, activation=\"relu\")(encoder_inputs)\n",
    "x = layers.Dense(32, activation=\"relu\")(x)\n",
    "x = layers.Dense(32, activation=\"relu\")(x)\n",
    "x = layers.Dense(16, activation=\"relu\")(x)\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\",\n",
    "                         bias_initializer='zeros', kernel_initializer='zeros',\n",
    "                         )(x)\n",
    "                         #activity_regularizer='l1')(x)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "#x = layers.BatchNormalization()(latent_inputs)\n",
    "x = layers.Dense(32, activation=\"relu\")(latent_inputs)\n",
    "x = layers.Dense(32, activation=\"relu\")(x)\n",
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "decoder_outputs = layers.Dense(input_dim, activation=\"relu\")(x)\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def train_step(self, data):\n",
    "        if isinstance(data, tuple):\n",
    "            data = data[0]\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = encoder(data)\n",
    "            reconstruction = decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                keras.losses.MSE(data, reconstruction)\n",
    "            )\n",
    "            reconstruction_loss *= features.shape[1]\n",
    "            kl_loss = 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n",
    "            kl_loss = tf.reduce_mean(kl_loss)\n",
    "            kl_loss *= -0.5\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        return {\n",
    "            \"loss\": total_loss,\n",
    "            \"reconstruction_loss\": reconstruction_loss,\n",
    "            \"kl_loss\": kl_loss,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "vae = VAE(encoder, decoder)\n",
    "vae.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001))\n",
    "vae.fit(features_scaled, epochs=50, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_vae, _, _  = encoder.predict(features_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20869, 2), (20869,), (20869,))"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_vae.shape, class_df['class'].shape, filename.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_vae_df = pd.DataFrame(features_vae, index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca6cb02a1a94419e8b8a14b78630a55c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(FigureWidget({\n",
       "    'data': [{'customdata': array([['./Samples/MDLib2.2/Sorted/Snare SNoff/Buzz/…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dysplay_embedding(\n",
    "    features_vae_df[ 0],\n",
    "    features_vae_df[1],\n",
    "    class_df['class'].values,\n",
    "    filename\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_reducer = umap.UMAP()\n",
    "embedding_vae = vae_reducer.fit_transform(features_vae)\n",
    "#embedding = features_vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6dd52ff4702421db91dfa56cc320b0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(FigureWidget({\n",
       "    'data': [{'customdata': array([['./Samples/MDLib2.2/Sorted/Snare SNoff/Buzz/…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dysplay_embedding(\n",
    "    embedding_vae[:, 0],\n",
    "    embedding_vae[:, 1],\n",
    "    class_df['class'].values,\n",
    "    filename\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "decoder_outputs = layers.Dense(nb_classes, activation=\"relu\")(latent_inputs)\n",
    "class_decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "\n",
    "class VAE_class(keras.Model):\n",
    "    def __init__(self, encoder, decoder, class_decoder, **kwargs):\n",
    "        super(VAE_class, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.class_decoder = class_decoder\n",
    "\n",
    "    def train_step(self, data):\n",
    "        if isinstance(data, tuple):\n",
    "            data = data[0]\n",
    "        features, classes = tf.split(data, [nb_features, nb_classes], 1)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(features)\n",
    "            reconstruction = self.decoder(z)\n",
    "            classes_recon = self.class_decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                keras.losses.MSE(features, reconstruction)\n",
    "            )\n",
    "            class_loss = tf.reduce_mean(\n",
    "                keras.losses.MSE(classes, classes_recon)\n",
    "            )\n",
    "            class_loss = class_loss*20\n",
    "            reconstruction_loss *= nb_features/10\n",
    "            class_loss *= nb_classes\n",
    "            kl_loss = 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n",
    "            kl_loss = tf.reduce_mean(kl_loss)\n",
    "            kl_loss *= -0.5\n",
    "            total_loss = reconstruction_loss + kl_loss + class_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        return {\n",
    "            \"loss\": total_loss,\n",
    "            \"reconstruction_loss\": reconstruction_loss,\n",
    "            \"kl_loss\": kl_loss,\n",
    "            \"class_loss\": class_loss,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE_class(encoder, decoder, class_decoder)\n",
    "vae.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001))\n",
    "data = np.concatenate((features_scaled, classes_onehot_df.values), axis=1)\n",
    "vae.fit(data, epochs=50, batch_size=128)\n",
    "\n",
    "features_vae2, _,_  = encoder.predict(features_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_vae_df2 = pd.DataFrame(features_vae2, index=features.index)\n",
    "dysplay_embedding(\n",
    "    features_vae_df2[ 0],\n",
    "    features_vae_df2[1],\n",
    "    class_df['class'].values,\n",
    "    filename\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dysplay_embedding(\n",
    "    features_vae_df[ 0],\n",
    "    features_vae_df[1],\n",
    "    class_df['class'].values,\n",
    "    filename\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
