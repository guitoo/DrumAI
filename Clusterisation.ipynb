{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from librosa.core import resample, load\n",
    "from librosa.util import fix_length\n",
    "from librosa import feature\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm as nb_tqdm\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import umap\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "from IPython.display import display\n",
    "import ipywidgets\n",
    "from ipywidgets import Output, VBox\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guillaume/miniconda3/envs/DrumAI/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (4,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('full.csv',index_col=0)\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>filename</th>\n",
       "      <th>dir_1</th>\n",
       "      <th>dir_2</th>\n",
       "      <th>class_Snare</th>\n",
       "      <th>class_Tom</th>\n",
       "      <th>dir_3</th>\n",
       "      <th>class_Cymbal</th>\n",
       "      <th>subclass_Cymbal_Crash</th>\n",
       "      <th>subclass_Cymbal_Ride</th>\n",
       "      <th>...</th>\n",
       "      <th>subclass_Shaken_Cabasa</th>\n",
       "      <th>class_Clave</th>\n",
       "      <th>class_Timpani</th>\n",
       "      <th>class_Agogo</th>\n",
       "      <th>class_Triangle</th>\n",
       "      <th>class_Djembe</th>\n",
       "      <th>class_Tabla</th>\n",
       "      <th>class_Darbuka</th>\n",
       "      <th>subclass_Shaken_Maracas</th>\n",
       "      <th>class_Cajon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./Samples/MDLib2.2/Sorted/Snare SNoff/Buzz/ST_...</td>\n",
       "      <td>ST_Snare_Buzz_0112.2.wav</td>\n",
       "      <td>Buzz</td>\n",
       "      <td>Snare SNoff</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./Samples/MDLib2.2/Sorted/Snare SNoff/Buzz/DI_...</td>\n",
       "      <td>DI_Snare_Buzz_0224.3.wav</td>\n",
       "      <td>Buzz</td>\n",
       "      <td>Snare SNoff</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./Samples/MDLib2.2/Sorted/Snare SNoff/Buzz/IN_...</td>\n",
       "      <td>IN_Snare_Buzz_0214.1.wav</td>\n",
       "      <td>Buzz</td>\n",
       "      <td>Snare SNoff</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./Samples/MDLib2.2/Sorted/Snare SNoff/Buzz/ST_...</td>\n",
       "      <td>ST_Snare_Buzz_0333.3.wav</td>\n",
       "      <td>Buzz</td>\n",
       "      <td>Snare SNoff</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./Samples/MDLib2.2/Sorted/Snare SNoff/Buzz/MN_...</td>\n",
       "      <td>MN_Snare_Buzz_0111.4.wav</td>\n",
       "      <td>Buzz</td>\n",
       "      <td>Snare SNoff</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>./Samples/MDLib2.2/Sorted/Snare SNoff/Buzz/IN_...</td>\n",
       "      <td>IN_Snare_Buzz_0112.3.wav</td>\n",
       "      <td>Buzz</td>\n",
       "      <td>Snare SNoff</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>./Samples/MDLib2.2/Sorted/Snare SNoff/Buzz/DI_...</td>\n",
       "      <td>DI_Snare_Buzz_0322.1.wav</td>\n",
       "      <td>Buzz</td>\n",
       "      <td>Snare SNoff</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>./Samples/MDLib2.2/Sorted/Snare SNoff/Buzz/MN_...</td>\n",
       "      <td>MN_Snare_Buzz_0321.2.wav</td>\n",
       "      <td>Buzz</td>\n",
       "      <td>Snare SNoff</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>./Samples/MDLib2.2/Sorted/Snare SNoff/Buzz/MN_...</td>\n",
       "      <td>MN_Snare_Buzz_0231.2.wav</td>\n",
       "      <td>Buzz</td>\n",
       "      <td>Snare SNoff</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>./Samples/MDLib2.2/Sorted/Snare SNoff/Buzz/ST_...</td>\n",
       "      <td>ST_Snare_Buzz_0232.4.wav</td>\n",
       "      <td>Buzz</td>\n",
       "      <td>Snare SNoff</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  \\\n",
       "0  ./Samples/MDLib2.2/Sorted/Snare SNoff/Buzz/ST_...   \n",
       "1  ./Samples/MDLib2.2/Sorted/Snare SNoff/Buzz/DI_...   \n",
       "2  ./Samples/MDLib2.2/Sorted/Snare SNoff/Buzz/IN_...   \n",
       "3  ./Samples/MDLib2.2/Sorted/Snare SNoff/Buzz/ST_...   \n",
       "4  ./Samples/MDLib2.2/Sorted/Snare SNoff/Buzz/MN_...   \n",
       "5  ./Samples/MDLib2.2/Sorted/Snare SNoff/Buzz/IN_...   \n",
       "6  ./Samples/MDLib2.2/Sorted/Snare SNoff/Buzz/DI_...   \n",
       "7  ./Samples/MDLib2.2/Sorted/Snare SNoff/Buzz/MN_...   \n",
       "8  ./Samples/MDLib2.2/Sorted/Snare SNoff/Buzz/MN_...   \n",
       "9  ./Samples/MDLib2.2/Sorted/Snare SNoff/Buzz/ST_...   \n",
       "\n",
       "                   filename dir_1        dir_2  class_Snare  class_Tom dir_3  \\\n",
       "0  ST_Snare_Buzz_0112.2.wav  Buzz  Snare SNoff          1.0        0.0     0   \n",
       "1  DI_Snare_Buzz_0224.3.wav  Buzz  Snare SNoff          1.0        0.0     0   \n",
       "2  IN_Snare_Buzz_0214.1.wav  Buzz  Snare SNoff          1.0        0.0     0   \n",
       "3  ST_Snare_Buzz_0333.3.wav  Buzz  Snare SNoff          1.0        0.0     0   \n",
       "4  MN_Snare_Buzz_0111.4.wav  Buzz  Snare SNoff          1.0        0.0     0   \n",
       "5  IN_Snare_Buzz_0112.3.wav  Buzz  Snare SNoff          1.0        0.0     0   \n",
       "6  DI_Snare_Buzz_0322.1.wav  Buzz  Snare SNoff          1.0        0.0     0   \n",
       "7  MN_Snare_Buzz_0321.2.wav  Buzz  Snare SNoff          1.0        0.0     0   \n",
       "8  MN_Snare_Buzz_0231.2.wav  Buzz  Snare SNoff          1.0        0.0     0   \n",
       "9  ST_Snare_Buzz_0232.4.wav  Buzz  Snare SNoff          1.0        0.0     0   \n",
       "\n",
       "   class_Cymbal  subclass_Cymbal_Crash  subclass_Cymbal_Ride  ...  \\\n",
       "0           0.0                    0.0                   0.0  ...   \n",
       "1           0.0                    0.0                   0.0  ...   \n",
       "2           0.0                    0.0                   0.0  ...   \n",
       "3           0.0                    0.0                   0.0  ...   \n",
       "4           0.0                    0.0                   0.0  ...   \n",
       "5           0.0                    0.0                   0.0  ...   \n",
       "6           0.0                    0.0                   0.0  ...   \n",
       "7           0.0                    0.0                   0.0  ...   \n",
       "8           0.0                    0.0                   0.0  ...   \n",
       "9           0.0                    0.0                   0.0  ...   \n",
       "\n",
       "   subclass_Shaken_Cabasa  class_Clave  class_Timpani  class_Agogo  \\\n",
       "0                     0.0          0.0            0.0          0.0   \n",
       "1                     0.0          0.0            0.0          0.0   \n",
       "2                     0.0          0.0            0.0          0.0   \n",
       "3                     0.0          0.0            0.0          0.0   \n",
       "4                     0.0          0.0            0.0          0.0   \n",
       "5                     0.0          0.0            0.0          0.0   \n",
       "6                     0.0          0.0            0.0          0.0   \n",
       "7                     0.0          0.0            0.0          0.0   \n",
       "8                     0.0          0.0            0.0          0.0   \n",
       "9                     0.0          0.0            0.0          0.0   \n",
       "\n",
       "   class_Triangle  class_Djembe  class_Tabla  class_Darbuka  \\\n",
       "0             0.0           0.0          0.0            0.0   \n",
       "1             0.0           0.0          0.0            0.0   \n",
       "2             0.0           0.0          0.0            0.0   \n",
       "3             0.0           0.0          0.0            0.0   \n",
       "4             0.0           0.0          0.0            0.0   \n",
       "5             0.0           0.0          0.0            0.0   \n",
       "6             0.0           0.0          0.0            0.0   \n",
       "7             0.0           0.0          0.0            0.0   \n",
       "8             0.0           0.0          0.0            0.0   \n",
       "9             0.0           0.0          0.0            0.0   \n",
       "\n",
       "   subclass_Shaken_Maracas  class_Cajon  \n",
       "0                      0.0          0.0  \n",
       "1                      0.0          0.0  \n",
       "2                      0.0          0.0  \n",
       "3                      0.0          0.0  \n",
       "4                      0.0          0.0  \n",
       "5                      0.0          0.0  \n",
       "6                      0.0          0.0  \n",
       "7                      0.0          0.0  \n",
       "8                      0.0          0.0  \n",
       "9                      0.0          0.0  \n",
       "\n",
       "[10 rows x 35 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20869/20869 [28:08<00:00, 12.36it/s] \n"
     ]
    }
   ],
   "source": [
    "SR=22050\n",
    "rms_list = []\n",
    "rms_cent_list = []\n",
    "zero_cross_list = []\n",
    "spect_cent_list = []\n",
    "spect_ro_list = []\n",
    "spect_cont_list = []\n",
    "mfcc_list = []\n",
    "index_list = []\n",
    "#data = data.sample(frac=0.2)\n",
    "for index, file in tqdm(zip(df.index, df['path']), total=len(df.index), position=0, leave=True):\n",
    "    try:\n",
    "        sound, _ = load(file, sr=SR)\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    index_list.append(index)\n",
    "    \n",
    "    rms = feature.rms(sound)[0]\n",
    "     #normalize by rms of attack frame\n",
    "    rms_centroid = (rms * np.arange(len(rms))).sum() / rms.sum()\n",
    "#     features.loc[index, 'rms_centroid'] = rms_centroid\n",
    "    rms_cent_list.append(rms_centroid)\n",
    "    \n",
    "    sound = sound/rms.max()\n",
    "    sound = fix_length(sound, 1024*(SR//1024))\n",
    "    \n",
    "    zero_cr = feature.zero_crossing_rate(sound)[0]\n",
    "#     columns = ['zero_cr_' + str(x) for x in range(zero_cr.shape[0])]\n",
    "#     for col, value in zip(columns, zero_cr):\n",
    "#         features.loc[index, col] = value\n",
    "    zero_cross_list.append(zero_cr)\n",
    "        \n",
    "    spect_cent = feature.spectral_centroid(sound, sr=SR)[0]\n",
    "#     columns = ['spect_cent_' + str(x) for x in range(spect_cent.shape[0])]\n",
    "#     for col, value in zip(columns, spect_cent):\n",
    "#         features.loc[index, col] = value\n",
    "    spect_cent_list.append(spect_cent)\n",
    "        \n",
    "    spect_ro = feature.spectral_rolloff(sound, sr=SR)[0]\n",
    "#     columns = ['spect_ro_' + str(x) for x in range(spect_ro.shape[0])]\n",
    "#     for col, value in zip(columns, spect_ro):\n",
    "#         features.loc[index, col] = value\n",
    "    spect_ro_list.append(spect_ro)\n",
    "        \n",
    "    rms = feature.rms(sound)[0]\n",
    "#     columns = ['rms_' + str(x) for x in range(rms.shape[0])]\n",
    "#     for col, value in zip(columns, rms):\n",
    "#         #features.loc[index, col] = value\n",
    "#         features.loc[index, 'norm_'+ col] = value\n",
    "    rms_list.append(rms)\n",
    "    \n",
    "        \n",
    "    spect_cont = feature.spectral_contrast(sound, sr=SR)\n",
    "#     for i in range (spect_cont.shape[0]):\n",
    "#         for j in range (spect_cont.shape[1]):\n",
    "#             col = 'spec_cont_' + str(i) + '_' + str(j)\n",
    "#             features.loc[index, col] = spect_cont[i][j]\n",
    "    spect_cont_list.append(spect_cont)\n",
    "    \n",
    "    mfcc = feature.mfcc(sound, sr=SR)\n",
    "    mfcc_list.append(mfcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "rms = np.stack(rms_list)\n",
    "rms_cent = np.stack(rms_cent_list)\n",
    "zero_cross = np.stack(zero_cross_list)\n",
    "spect_cent = np.stack(spect_cent_list)\n",
    "spect_ro = np.stack(spect_ro_list)\n",
    "spect_cont = np.stack(spect_cont_list)\n",
    "mfcc = np.stack(mfcc_list)\n",
    "index = np.stack(index_list)\n",
    "\n",
    "np.save('feature_rms.npy', rms)\n",
    "np.save('feature_rms_centroid.npy', rms_cent)\n",
    "np.save('feature_zero_crossing_rate.npy', zero_cross)\n",
    "np.save('feature_spectral_centroid.npy', spect_cent)\n",
    "np.save('feature_spectral_rolloff.npy', spect_ro)\n",
    "np.save('feature_spectral_contour.npy', spect_cont)\n",
    "np.save('feature_mfcc.npy', mfcc)\n",
    "np.save('index.npy', index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms = np.load('feature_rms.npy')\n",
    "rms_cent = np.load('feature_rms_centroid.npy')\n",
    "zero_cross = np.load('feature_zero_crossing_rate.npy')\n",
    "spect_cent = np.load('feature_spectral_centroid.npy')\n",
    "spect_ro = np.load('feature_spectral_rolloff.npy')\n",
    "spect_cont = np.load('feature_spectral_contour.npy')\n",
    "mfcc = np.load('feature_mfcc.npy')\n",
    "index = np.load('index.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20869,)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20869, 474)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = index.shape[0]\n",
    "features = np.hstack([\n",
    "    rms.reshape(size,-1),\n",
    "    rms_cent.reshape(size,-1),\n",
    "    zero_cross.reshape(size,-1),\n",
    "    spect_cent.reshape(size,-1),\n",
    "    spect_ro.reshape(size,-1),\n",
    "    spect_cont.reshape(size,-1),\n",
    "                  ])\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "features.to_csv('features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv('features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['path', 'filename', 'dir_1', 'dir_2', 'class_Snare', 'class_Tom',\n",
       "       'dir_3', 'class_Cymbal', 'subclass_Cymbal_Crash',\n",
       "       'subclass_Cymbal_Ride', 'class_Hat', 'class_Kick', 'subclass_Hat_Open',\n",
       "       'subclass_Hat_Close', 'class_Bongo', 'subclass_Cymbal_Chinese',\n",
       "       'subclass_Cymbal_Splash', 'class_Conga', 'class_Gong', 'class_Cowbell',\n",
       "       'class_Rimshot', 'class_Clap', 'class_Shaken', 'subclass_Shaken_Shaker',\n",
       "       'subclass_Shaken_Tambourin', 'subclass_Shaken_Cabasa', 'class_Clave',\n",
       "       'class_Timpani', 'class_Agogo', 'class_Triangle', 'class_Djembe',\n",
       "       'class_Tabla', 'class_Darbuka', 'subclass_Shaken_Maracas',\n",
       "       'class_Cajon'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [c for c in df.columns if c.startswith('class_')]\n",
    "cymb_classes = [c for c in df.columns if c.startswith('subclass_Cymbal')]\n",
    "shak_classes = [c for c in df.columns if c.startswith('subclass_Shaken')]\n",
    "hat_classes = [c for c in df.columns if c.startswith('subclass_Hat')]\n",
    "\n",
    "all_classes = classes + cymb_classes + shak_classes + hat_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['subclass_Cymbal_Crash',\n",
       " 'subclass_Cymbal_Ride',\n",
       " 'subclass_Cymbal_Chinese',\n",
       " 'subclass_Cymbal_Splash']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cymb_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_df = pd.DataFrame()\n",
    "\n",
    "class_df['class'] = df[all_classes].idxmax(axis=1)\n",
    "\n",
    "mask = df[all_classes].sum(axis=1) == 0\n",
    "class_df.loc[mask, 'class'] = 'Error'\n",
    "\n",
    "cymbales = (df['class_Cymbal'] == 1) & (df[cymb_classes].sum(axis=1) > 0)\n",
    "class_df.loc[cymbales, 'class'] = df.loc[cymbales, cymb_classes].idxmax(axis=1)\n",
    "\n",
    "shaken = (df['class_Shaken'] == 1) & (df[shak_classes].sum(axis=1) > 0)\n",
    "class_df.loc[shaken, 'class'] = df.loc[shaken, shak_classes].idxmax(axis=1)\n",
    "\n",
    "hats = (df['class_Hat'] == 1) & (df[hat_classes].sum(axis=1) > 0)\n",
    "class_df.loc[hats, 'class'] = df.loc[hats, hat_classes].idxmax(axis=1)\n",
    "# class_df['class'] = df[hat_classes + ['class_Hat']].idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10639       subclass_Shaken_Shaker\n",
       "10703       subclass_Shaken_Shaker\n",
       "10736    subclass_Shaken_Tambourin\n",
       "10763    subclass_Shaken_Tambourin\n",
       "10795       subclass_Shaken_Cabasa\n",
       "                   ...            \n",
       "20776    subclass_Shaken_Tambourin\n",
       "20777       subclass_Shaken_Shaker\n",
       "20779      subclass_Shaken_Maracas\n",
       "20853    subclass_Shaken_Tambourin\n",
       "20863    subclass_Shaken_Tambourin\n",
       "Length: 140, dtype: object"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[shaken, shak_classes].idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7488</th>\n",
       "      <td>subclass_Cymbal_Crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7489</th>\n",
       "      <td>subclass_Cymbal_Crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7490</th>\n",
       "      <td>subclass_Cymbal_Crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7491</th>\n",
       "      <td>subclass_Cymbal_Crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7492</th>\n",
       "      <td>subclass_Cymbal_Crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20852</th>\n",
       "      <td>subclass_Hat_Close</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20853</th>\n",
       "      <td>subclass_Shaken_Tambourin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20855</th>\n",
       "      <td>subclass_Hat_Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20859</th>\n",
       "      <td>subclass_Hat_Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20863</th>\n",
       "      <td>subclass_Shaken_Tambourin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1917 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           class\n",
       "7488       subclass_Cymbal_Crash\n",
       "7489       subclass_Cymbal_Crash\n",
       "7490       subclass_Cymbal_Crash\n",
       "7491       subclass_Cymbal_Crash\n",
       "7492       subclass_Cymbal_Crash\n",
       "...                          ...\n",
       "20852         subclass_Hat_Close\n",
       "20853  subclass_Shaken_Tambourin\n",
       "20855          subclass_Hat_Open\n",
       "20859          subclass_Hat_Open\n",
       "20863  subclass_Shaken_Tambourin\n",
       "\n",
       "[1917 rows x 1 columns]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_df[class_df['class'].str.startswith('subclass_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dysplay_embedding(x, y, classes, files):\n",
    "    embedding_vae_df = pd.DataFrame({\n",
    "        'x': x,\n",
    "        'y': y,\n",
    "        'class': classes,\n",
    "        'file': files    \n",
    "                         })\n",
    "    \n",
    "    scatter = px.scatter(\n",
    "        embedding_vae_df,\n",
    "        x='x',\n",
    "        y='y',\n",
    "        color='class',\n",
    "        hover_data=['file']\n",
    "    )\n",
    "    figure = go.FigureWidget(scatter)\n",
    "\n",
    "    out = Output()\n",
    "\n",
    "    @out.capture(clear_output=False, wait=True)\n",
    "    def play_sound(trace, points, selector):\n",
    "        if len(points.point_inds) != 1:\n",
    "           return\n",
    "        #print(points)\n",
    "        out.clear_output()\n",
    "        path = trace.customdata[points.point_inds[0]][0]\n",
    "        #print(path)\n",
    "        sound, sr = load(path)\n",
    "        IPython.display.display(IPython.display.Audio(sound, rate=sr, autoplay=True))\n",
    "\n",
    "    for trace in figure.data:\n",
    "        trace.on_click(play_sound)\n",
    "\n",
    "\n",
    "    box = VBox([figure, out])\n",
    "    display(box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler \n",
    "# scaler = StandardScaler()\n",
    "# features_scaled = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = umap.UMAP()\n",
    "embedding = reducer.fit_transform(features_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20869, 1)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_df = class_df.loc[index]\n",
    "class_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = df.loc[index,'path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f3d6bf83b844022b325be4a556d56d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(FigureWidget({\n",
       "    'data': [{'customdata': array([['./Samples/MDLib2.2/Sorted/Snare SNoff/Buzz/…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dysplay_embedding(\n",
    "    embedding[:, 0],\n",
    "    embedding[:, 1],\n",
    "    class_df['class'].values,\n",
    "    filename\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rms_cent = rms_cent.reshape(-1, 1)\n",
    "# rms = rms.reshape(-1,rms.shape[1], 1)\n",
    "features_input = dict(\n",
    "    rms=rms,\n",
    "    rms_centroid=rms_cent,\n",
    "    zero_crossing=zero_cross,\n",
    "    spectral_centroid=spect_cent,\n",
    "    spectral_rolloff=spect_ro,\n",
    "    spectral_contour=spect_cont,\n",
    "    mfcc=mfcc\n",
    ")\n",
    "for key, feature in list(features_input.items()):\n",
    "    if feature.shape[-1] !=1:\n",
    "        features_input[key] = np.expand_dims(feature, axis=feature.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = {}\n",
    "features_scaled = {}\n",
    "for key, feature in list(features_input.items()):\n",
    "    scaler[key] = {}\n",
    "    scaler[key]['max'] = max(feature.max(), -feature.min())\n",
    "    features_scaled[key] = feature/scaler[key]['max']\n",
    "#     scaler[key]['mean'] = feature.mean()\n",
    "# #     scaler[key]['mean'] = feature.mean(axis=0)\n",
    "#     f = feature-scaler[key]['mean']\n",
    "#     scaler[key]['std'] = f.std()\n",
    "# #     scaler[key]['std'] = f.std(axis=0)\n",
    "#     features_scaled[key] = f/scaler[key]['std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rms 0.0 1.0\n",
      "rms_centroid 0.0 1.0\n",
      "zero_crossing 0.0 1.0\n",
      "spectral_centroid 0.0 1.0\n",
      "spectral_rolloff 0.0 1.0\n",
      "spectral_contour 0.0 1.0\n",
      "mfcc -1.0 0.3804038\n"
     ]
    }
   ],
   "source": [
    "for key, feature in list(features_scaled.items()):\n",
    "    print(key, feature.min(), feature.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rms shape: (43, 1)\n",
      "rms_centroid shape: (1,)\n",
      "zero_crossing shape: (43, 1)\n",
      "spectral_centroid shape: (43, 1)\n",
      "spectral_rolloff shape: (43, 1)\n",
      "spectral_contour shape: (7, 43, 1)\n",
      "mfcc shape: (20, 43, 1)\n"
     ]
    }
   ],
   "source": [
    "for key, value in features_scaled.items():\n",
    "    print(f\"{key} shape: {value.shape[1:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_63 (InputLayer)           [(None, 20, 43, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_57 (InputLayer)           [(None, 43, 1)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_59 (InputLayer)           [(None, 43, 1)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_60 (InputLayer)           [(None, 43, 1)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_61 (InputLayer)           [(None, 43, 1)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 20, 43, 8)    80          input_63[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_62 (InputLayer)           [(None, 7, 43, 1)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_72 (Conv1D)              (None, 43, 4)        16          input_57[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_75 (Conv1D)              (None, 43, 4)        16          input_59[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_78 (Conv1D)              (None, 43, 4)        16          input_60[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_81 (Conv1D)              (None, 43, 4)        16          input_61[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_42 (MaxPooling2D) (None, 10, 21, 8)    0           conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 7, 43, 4)     40          input_62[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_72 (MaxPooling1D) (None, 21, 4)        0           conv1d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_75 (MaxPooling1D) (None, 21, 4)        0           conv1d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_78 (MaxPooling1D) (None, 21, 4)        0           conv1d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_81 (MaxPooling1D) (None, 21, 4)        0           conv1d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 10, 21, 16)   1168        max_pooling2d_42[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_46 (MaxPooling2D) (None, 3, 21, 4)     0           conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_73 (Conv1D)              (None, 21, 8)        104         max_pooling1d_72[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_76 (Conv1D)              (None, 21, 8)        104         max_pooling1d_75[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_79 (Conv1D)              (None, 21, 8)        104         max_pooling1d_78[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_82 (Conv1D)              (None, 21, 8)        104         max_pooling1d_81[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_43 (MaxPooling2D) (None, 5, 10, 16)    0           conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 3, 21, 8)     296         max_pooling2d_46[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_73 (MaxPooling1D) (None, 10, 8)        0           conv1d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_76 (MaxPooling1D) (None, 10, 8)        0           conv1d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_79 (MaxPooling1D) (None, 10, 8)        0           conv1d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_82 (MaxPooling1D) (None, 10, 8)        0           conv1d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 5, 10, 32)    4640        max_pooling2d_43[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_47 (MaxPooling2D) (None, 1, 10, 8)     0           conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_74 (Conv1D)              (None, 10, 16)       400         max_pooling1d_73[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_77 (Conv1D)              (None, 10, 16)       400         max_pooling1d_76[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_80 (Conv1D)              (None, 10, 16)       400         max_pooling1d_79[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_83 (Conv1D)              (None, 10, 16)       400         max_pooling1d_82[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_44 (MaxPooling2D) (None, 2, 5, 32)     0           conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 1, 10, 16)    1168        max_pooling2d_47[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_74 (MaxPooling1D) (None, 5, 16)        0           conv1d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_77 (MaxPooling1D) (None, 5, 16)        0           conv1d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_80 (MaxPooling1D) (None, 5, 16)        0           conv1d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_83 (MaxPooling1D) (None, 5, 16)        0           conv1d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_45 (MaxPooling2D) (None, 1, 5, 32)     0           max_pooling2d_44[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_48 (MaxPooling2D) (None, 1, 5, 16)     0           conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_58 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_36 (Flatten)            (None, 80)           0           max_pooling1d_74[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_37 (Flatten)            (None, 80)           0           max_pooling1d_77[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_38 (Flatten)            (None, 80)           0           max_pooling1d_80[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_39 (Flatten)            (None, 80)           0           max_pooling1d_83[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_40 (Flatten)            (None, 160)          0           max_pooling2d_45[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_41 (Flatten)            (None, 80)           0           max_pooling2d_48[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 561)          0           input_58[0][0]                   \n",
      "                                                                 flatten_36[0][0]                 \n",
      "                                                                 flatten_37[0][0]                 \n",
      "                                                                 flatten_38[0][0]                 \n",
      "                                                                 flatten_39[0][0]                 \n",
      "                                                                 flatten_40[0][0]                 \n",
      "                                                                 flatten_41[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_143 (Dense)               (None, 32)           17984       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_144 (Dense)               (None, 16)           528         dense_143[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_145 (Dense)               (None, 8)            136         dense_144[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 2)            18          dense_145[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 2)            18          dense_145[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sampling_6 (Sampling)           (None, 2)            0           z_mean[0][0]                     \n",
      "                                                                 z_log_var[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 28,156\n",
      "Trainable params: 28,156\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_dim=2\n",
    "\n",
    "rms_input = keras.Input(shape=features_input['rms'].shape[1:])\n",
    "rms_cent_input = keras.Input(shape=features_input['rms_centroid'].shape[1:])\n",
    "zero_cross_input = keras.Input(shape=features_input['zero_crossing'].shape[1:])\n",
    "spect_cent_input = keras.Input(shape=features_input['spectral_centroid'].shape[1:])\n",
    "spect_ro_input = keras.Input(shape=features_input['spectral_rolloff'].shape[1:])\n",
    "spect_cont_input = keras.Input(shape=features_input['spectral_contour'].shape[1:])\n",
    "mfcc_input = keras.Input(shape=features_input['mfcc'].shape[1:])\n",
    "\n",
    "x=rms_input\n",
    "for filters in [4,8,16]:\n",
    "    x = layers.Conv1D(filters,3,activation='relu',padding='same')(x)\n",
    "    x = layers.MaxPooling1D(2)(x)\n",
    "rms_out = layers.Flatten()(x)\n",
    "\n",
    "x=zero_cross_input\n",
    "for filters in [4,8,16]:\n",
    "    x = layers.Conv1D(filters,3,activation='relu',padding='same')(x)\n",
    "    x = layers.MaxPooling1D(2)(x)\n",
    "zero_cross_out = layers.Flatten()(x)\n",
    "\n",
    "x=spect_cent_input\n",
    "for filters in [4,8,16]:\n",
    "    x = layers.Conv1D(filters,3,activation='relu',padding='same')(x)\n",
    "    x = layers.MaxPooling1D(2)(x)\n",
    "spect_cent_out = layers.Flatten()(x)\n",
    "\n",
    "x=spect_ro_input\n",
    "for filters in [4,8,16]:\n",
    "    x = layers.Conv1D(filters,3,activation='relu',padding='same')(x)\n",
    "    x = layers.MaxPooling1D(2)(x)\n",
    "spect_ro_out = layers.Flatten()(x)\n",
    "\n",
    "x=mfcc_input\n",
    "for filters in [8,16,32]:\n",
    "    x = layers.Conv2D(filters, (3,3), activation='tanh',padding='same')(x)\n",
    "    x = layers.MaxPooling2D((2,2))(x)\n",
    "x = layers.MaxPooling2D((2,1))(x)\n",
    "mfcc_out = layers.Flatten()(x)\n",
    "\n",
    "x=spect_cont_input\n",
    "for filters in [4,8]:\n",
    "    x = layers.Conv2D(filters, (3,3), activation='relu',padding='same')(x)\n",
    "    x = layers.MaxPooling2D((2,2))(x)\n",
    "x = layers.Conv2D(16, (3,3), activation='relu',padding='same')(x)\n",
    "x = layers.MaxPooling2D((1,2))(x)\n",
    "spect_cont_out = layers.Flatten()(x)\n",
    "    \n",
    "x = layers.Concatenate()((rms_cent_input, rms_out, zero_cross_out, spect_cent_out,\n",
    "                          spect_ro_out, mfcc_out, spect_cont_out))\n",
    "\n",
    "for size in [32, 16, 8]:\n",
    "    x = layers.Dense(size, activation='relu')(x)\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "\n",
    "inputs = dict(\n",
    "    rms=rms_input,\n",
    "    rms_centroid=rms_cent_input,\n",
    "    zero_crossing=zero_cross_input,\n",
    "    spectral_centroid=spect_cent_input,\n",
    "    spectral_rolloff=spect_ro_input,\n",
    "    spectral_contour=spect_cont_input,\n",
    "    mfcc=mfcc_input\n",
    ")\n",
    "outputs =  (z_mean, z_log_var, z)\n",
    "\n",
    "encoder = keras.Model(inputs, outputs, name=\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-213-649908e3efb0>, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-213-649908e3efb0>\"\u001b[0;36m, line \u001b[0;32m11\u001b[0m\n\u001b[0;31m    x = layers.Dense(16, , activation=\"relu\")(latent_inputs)\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "\n",
    "x = layers.Dense(1 * 6 * 16, activation=\"relu\")(latent_inputs)\n",
    "x = layers.Reshape((1, 6, 16))(x)\n",
    "x = layers.Conv2DTranspose(32, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.Conv2DTranspose(16, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.Conv2DTranspose(1, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
    "x = layers.Cropping2D(cropping=((0,1),(2,3)))(x)\n",
    "spect_cont_out = x\n",
    "\n",
    "x = layers.Dense(16, , activation=\"relu\")(latent_inputs)\n",
    "x = layers.Dense(3 * 6 * 16, activation=\"relu\")(x)\n",
    "x = layers.Reshape((3, 6, 16))(x)\n",
    "x = layers.Conv2DTranspose(32, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.Conv2DTranspose(16, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.Conv2DTranspose(1, 3, activation=\"tanh\", padding=\"same\")(x)\n",
    "x = layers.Cropping2D(cropping=((2,2),(2,3)))(x)\n",
    "mfcc_out = x\n",
    "\n",
    "# x = layers.Dense(16, activation=\"relu\")(latent_inputs)\n",
    "# x = layers.Dense(32, activation=\"relu\")(x)\n",
    "# x = layers.Dense(64, activation=\"relu\")(x)\n",
    "# x = layers.Dense(20*43, activation=\"relu\")(x)\n",
    "# mfcc_out = layers.Reshape((20, 43, 1))(x)\n",
    "\n",
    "x = layers.Dense(6 * 16, activation=\"relu\")(latent_inputs)\n",
    "x = layers.Reshape((6, 16))(x)\n",
    "x = layers.Conv1DTranspose(32, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.Conv1DTranspose(16, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.Conv1DTranspose(1, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
    "x = layers.Cropping1D(cropping=(2,3))(x)\n",
    "rms_out = x\n",
    "\n",
    "x = layers.Dense(6 * 16, activation=\"relu\")(latent_inputs)\n",
    "x = layers.Reshape((6, 16))(x)\n",
    "x = layers.Conv1DTranspose(32, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.Conv1DTranspose(16, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.Conv1DTranspose(1, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
    "x = layers.Cropping1D(cropping=(2,3))(x)\n",
    "zero_cross_out = x\n",
    "\n",
    "x = layers.Dense(6 * 16, activation=\"relu\")(latent_inputs)\n",
    "x = layers.Reshape((6, 16))(x)\n",
    "x = layers.Conv1DTranspose(32, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.Conv1DTranspose(16, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.Conv1DTranspose(1, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
    "x = layers.Cropping1D(cropping=(2,3))(x)\n",
    "spect_cent_out = x\n",
    "\n",
    "x = layers.Dense(6 * 16, activation=\"relu\")(latent_inputs)\n",
    "x = layers.Reshape((6, 16))(x)\n",
    "x = layers.Conv1DTranspose(32, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.Conv1DTranspose(16, 3, activation=\"relu\",, padding=\"same\")(x)\n",
    "x = layers.Conv1DTranspose(1, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
    "x = layers.Cropping1D(cropping=(2,3))(x)\n",
    "spect_ro_out = x\n",
    "\n",
    "for size in (4,8,16):\n",
    "    x = layers.Dense(size, activation=\"relu\")(latent_inputs)\n",
    "rms_cent_out = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "outputs = dict(\n",
    "    rms=rms_out,\n",
    "    rms_centroid=rms_cent_out,\n",
    "    zero_crossing=zero_cross_out,\n",
    "    spectral_centroid=spect_cent_out,\n",
    "    spectral_rolloff=spect_ro_out,\n",
    "    spectral_contour=spect_cont_out,\n",
    "    mfcc=mfcc_out\n",
    ")\n",
    "decoder_outputs = x\n",
    "#decoder_outputs = layers.Dense(input_dim, activation=\"relu\")(x)\n",
    "decoder = keras.Model(latent_inputs, outputs, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def train_step(self, data):\n",
    "        if isinstance(data, tuple):\n",
    "            data = data[0]\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = encoder(data)\n",
    "            reconstruction = decoder(z)\n",
    "            \n",
    "            rms_loss = tf.reduce_mean(\n",
    "                keras.losses.binary_crossentropy(data['rms'], reconstruction['rms'])\n",
    "            )\n",
    "            rms_loss *= 43\n",
    "            zero_crossing_loss = tf.reduce_mean(\n",
    "                keras.losses.binary_crossentropy(data['zero_crossing'], reconstruction['zero_crossing'])\n",
    "            )\n",
    "            zero_crossing_loss *= 43\n",
    "            spectral_centroid_loss = tf.reduce_mean(\n",
    "                keras.losses.binary_crossentropy(data['spectral_centroid'], reconstruction['spectral_centroid'])\n",
    "            )\n",
    "            spectral_centroid_loss *= 43\n",
    "            spectral_rolloff_loss = tf.reduce_mean(\n",
    "                keras.losses.binary_crossentropy(data['spectral_rolloff'], reconstruction['spectral_rolloff'])\n",
    "            )\n",
    "            spectral_rolloff_loss *= 43\n",
    "            mfcc_loss = tf.reduce_mean(\n",
    "                keras.losses.MSE(data['mfcc'], reconstruction['mfcc'])\n",
    "            )\n",
    "            mfcc_loss *= 20*43\n",
    "            spectral_contour_loss = tf.reduce_mean(\n",
    "                keras.losses.MSE(data['spectral_contour'], reconstruction['spectral_contour'])\n",
    "            )\n",
    "            spectral_contour_loss *= 7*43\n",
    "            rms_cent_loss = tf.reduce_mean(\n",
    "                keras.losses.binary_crossentropy(data['rms_centroid'], reconstruction['rms_centroid'])\n",
    "            )\n",
    "\n",
    "            reconstruction_loss = rms_loss + mfcc_loss + rms_cent_loss + zero_crossing_loss \\\n",
    "                                + spectral_centroid_loss + spectral_rolloff_loss+ spectral_contour_loss\n",
    "#             reconstruction_loss = mfcc_loss\n",
    "            \n",
    "            kl_loss = 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n",
    "            kl_loss = tf.reduce_mean(kl_loss)\n",
    "            kl_loss *= -0.5\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        return {\n",
    "            \"loss\": total_loss,\n",
    "            \"reconstruction_loss\": reconstruction_loss,\n",
    "            \"kl_loss\": kl_loss,\n",
    "            \"mfcc_loss\": mfcc_loss\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "164/164 [==============================] - 9s 52ms/step - loss: 99.1254 - reconstruction_loss: 97.2633 - kl_loss: 1.8621 - mfcc_loss: 8.0185\n",
      "Epoch 2/20\n",
      "164/164 [==============================] - 9s 54ms/step - loss: 77.3087 - reconstruction_loss: 75.4920 - kl_loss: 1.8167 - mfcc_loss: 8.0167\n",
      "Epoch 3/20\n",
      "164/164 [==============================] - 9s 54ms/step - loss: 73.6531 - reconstruction_loss: 71.6482 - kl_loss: 2.0049 - mfcc_loss: 7.9859\n",
      "Epoch 4/20\n",
      "164/164 [==============================] - 9s 52ms/step - loss: 71.5316 - reconstruction_loss: 69.3523 - kl_loss: 2.1793 - mfcc_loss: 7.8716\n",
      "Epoch 5/20\n",
      "164/164 [==============================] - 9s 55ms/step - loss: 69.8536 - reconstruction_loss: 67.4844 - kl_loss: 2.3692 - mfcc_loss: 7.8741\n",
      "Epoch 6/20\n",
      "164/164 [==============================] - 9s 56ms/step - loss: 68.9230 - reconstruction_loss: 66.4902 - kl_loss: 2.4329 - mfcc_loss: 7.8418\n",
      "Epoch 7/20\n",
      "164/164 [==============================] - 9s 57ms/step - loss: 67.7734 - reconstruction_loss: 65.3056 - kl_loss: 2.4678 - mfcc_loss: 7.8771\n",
      "Epoch 8/20\n",
      "164/164 [==============================] - 9s 56ms/step - loss: 67.2690 - reconstruction_loss: 64.8728 - kl_loss: 2.3962 - mfcc_loss: 7.8248\n",
      "Epoch 9/20\n",
      "164/164 [==============================] - 9s 55ms/step - loss: 66.4554 - reconstruction_loss: 64.1095 - kl_loss: 2.3458 - mfcc_loss: 7.8503\n",
      "Epoch 10/20\n",
      "164/164 [==============================] - 9s 56ms/step - loss: 66.2591 - reconstruction_loss: 63.9616 - kl_loss: 2.2975 - mfcc_loss: 7.8156\n",
      "Epoch 11/20\n",
      "164/164 [==============================] - 9s 56ms/step - loss: 66.1204 - reconstruction_loss: 63.8465 - kl_loss: 2.2739 - mfcc_loss: 7.7871\n",
      "Epoch 12/20\n",
      "164/164 [==============================] - 9s 56ms/step - loss: 65.6961 - reconstruction_loss: 63.4287 - kl_loss: 2.2674 - mfcc_loss: 7.8360\n",
      "Epoch 13/20\n",
      "164/164 [==============================] - 9s 56ms/step - loss: 65.7891 - reconstruction_loss: 63.5308 - kl_loss: 2.2583 - mfcc_loss: 7.7978\n",
      "Epoch 14/20\n",
      "164/164 [==============================] - 9s 56ms/step - loss: 65.3987 - reconstruction_loss: 63.1322 - kl_loss: 2.2666 - mfcc_loss: 7.8521\n",
      "Epoch 15/20\n",
      "164/164 [==============================] - 9s 56ms/step - loss: 65.5661 - reconstruction_loss: 63.2999 - kl_loss: 2.2661 - mfcc_loss: 7.8243\n",
      "Epoch 16/20\n",
      "164/164 [==============================] - 9s 56ms/step - loss: 65.3935 - reconstruction_loss: 63.1246 - kl_loss: 2.2688 - mfcc_loss: 7.8259\n",
      "Epoch 17/20\n",
      "164/164 [==============================] - 9s 56ms/step - loss: 65.2640 - reconstruction_loss: 63.0005 - kl_loss: 2.2635 - mfcc_loss: 7.8446\n",
      "Epoch 18/20\n",
      "164/164 [==============================] - 9s 55ms/step - loss: 64.9829 - reconstruction_loss: 62.7144 - kl_loss: 2.2685 - mfcc_loss: 7.8374\n",
      "Epoch 19/20\n",
      "164/164 [==============================] - 9s 57ms/step - loss: 65.3749 - reconstruction_loss: 63.0987 - kl_loss: 2.2762 - mfcc_loss: 7.8204\n",
      "Epoch 20/20\n",
      "164/164 [==============================] - 9s 56ms/step - loss: 65.1800 - reconstruction_loss: 62.9131 - kl_loss: 2.2669 - mfcc_loss: 7.8045\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f36baa35fd0>"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae = VAE(encoder, decoder)\n",
    "vae.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001))\n",
    "vae.fit(features_scaled, epochs=20, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "latent_dim = 2\n",
    "input_dim = features.shape[1]\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(input_dim))\n",
    "x = layers.Dense(64, activation=\"relu\")(encoder_inputs)\n",
    "x = layers.Dense(32, activation=\"relu\")(x)\n",
    "x = layers.Dense(32, activation=\"relu\")(x)\n",
    "x = layers.Dense(16, activation=\"relu\")(x)\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\",\n",
    "                         bias_initializer='zeros', kernel_initializer='zeros',\n",
    "                         )(x)\n",
    "                         #activity_regularizer='l1')(x)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "#x = layers.BatchNormalization()(latent_inputs)\n",
    "x = layers.Dense(32, activation=\"relu\")(latent_inputs)\n",
    "x = layers.Dense(32, activation=\"relu\")(x)\n",
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "decoder_outputs = layers.Dense(input_dim, activation=\"relu\")(x)\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def train_step(self, data):\n",
    "        if isinstance(data, tuple):\n",
    "            data = data[0]\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = encoder(data)\n",
    "            reconstruction = decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                keras.losses.MSE(data, reconstruction)\n",
    "            )\n",
    "            reconstruction_loss *= features.shape[1]\n",
    "            kl_loss = 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n",
    "            kl_loss = tf.reduce_mean(kl_loss)\n",
    "            kl_loss *= -0.5\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        return {\n",
    "            \"loss\": total_loss,\n",
    "            \"reconstruction_loss\": reconstruction_loss,\n",
    "            \"kl_loss\": kl_loss,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "vae = VAE(encoder, decoder)\n",
    "vae.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001))\n",
    "vae.fit(features_scaled, epochs=50, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_vae, _, _  = encoder.predict(features_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.34269089, -0.4479463 ],\n",
       "       [-0.26894003,  0.4878795 ],\n",
       "       [-0.18906212,  0.5238928 ],\n",
       "       ...,\n",
       "       [ 0.91784066, -0.14022548],\n",
       "       [ 1.392837  ,  0.24187748],\n",
       "       [-1.1240165 , -1.4678499 ]], dtype=float32)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20869, 2), (20869,), (20869,))"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_vae.shape, class_df['class'].shape, filename.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_vae_df = pd.DataFrame(features_vae, index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f77a8cf2194e4dfc8f95282c8b46f667",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(FigureWidget({\n",
       "    'data': [{'customdata': array([['./Samples/MDLib2.2/Sorted/Snare SNoff/Buzz/…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dysplay_embedding(\n",
    "    features_vae_df[ 0],\n",
    "    features_vae_df[1],\n",
    "    class_df['class'].values,\n",
    "    filename\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_reducer = umap.UMAP()\n",
    "embedding_vae = vae_reducer.fit_transform(features_vae)\n",
    "#embedding = features_vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dysplay_embedding(\n",
    "    embedding_vae[:, 0],\n",
    "    embedding_vae[:, 1],\n",
    "    class_df['class'].values,\n",
    "    filename\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_onehot_df = df[all_classes]\n",
    "classes_onehot_df = classes_onehot_df.loc[features.index]\n",
    "nb_classes =  classes_onehot_df.shape[1]\n",
    "nb_features = features.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "decoder_outputs = layers.Dense(nb_classes, activation=\"relu\")(latent_inputs)\n",
    "class_decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "\n",
    "class VAE_class(keras.Model):\n",
    "    def __init__(self, encoder, decoder, class_decoder, **kwargs):\n",
    "        super(VAE_class, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.class_decoder = class_decoder\n",
    "\n",
    "    def train_step(self, data):\n",
    "        if isinstance(data, tuple):\n",
    "            data = data[0]\n",
    "        features, classes = tf.split(data, [nb_features, nb_classes], 1)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(features)\n",
    "            reconstruction = self.decoder(z)\n",
    "            classes_recon = self.class_decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                keras.losses.MSE(features, reconstruction)\n",
    "            )\n",
    "            class_loss = tf.reduce_mean(\n",
    "                keras.losses.MSE(classes, classes_recon)\n",
    "            )\n",
    "            class_loss = class_loss*20\n",
    "            reconstruction_loss *= nb_features/10\n",
    "            class_loss *= nb_classes\n",
    "            kl_loss = 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n",
    "            kl_loss = tf.reduce_mean(kl_loss)\n",
    "            kl_loss *= -0.5\n",
    "            total_loss = reconstruction_loss + kl_loss + class_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        return {\n",
    "            \"loss\": total_loss,\n",
    "            \"reconstruction_loss\": reconstruction_loss,\n",
    "            \"kl_loss\": kl_loss,\n",
    "            \"class_loss\": class_loss,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE_class(encoder, decoder, class_decoder)\n",
    "vae.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001))\n",
    "data = np.concatenate((features_scaled, classes_onehot_df.values), axis=1)\n",
    "vae.fit(data, epochs=50, batch_size=128)\n",
    "\n",
    "features_vae2, _,_  = encoder.predict(features_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_vae_df2 = pd.DataFrame(features_vae2, index=features.index)\n",
    "dysplay_embedding(\n",
    "    features_vae_df2[ 0],\n",
    "    features_vae_df2[1],\n",
    "    class_df['class'].values,\n",
    "    filename\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dysplay_embedding(\n",
    "    features_vae_df[ 0],\n",
    "    features_vae_df[1],\n",
    "    class_df['class'].values,\n",
    "    filename\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
